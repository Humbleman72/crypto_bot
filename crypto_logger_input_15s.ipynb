{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jKtLwsCCqsmH"
   },
   "source": [
    "Cryptocurrency trading bot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# File:        cryptocurrency/crypto_logger_base.py\n",
    "# By:          Samuel Duclos\n",
    "# For          Myself\n",
    "# Description: Simple Binance logger base class.\n",
    "\n",
    "# Library imports.\n",
    "from cryptocurrency.resample import resample\n",
    "from binance.client import Client\n",
    "from abc import abstractmethod, ABC\n",
    "from time import sleep, time\n",
    "from os.path import exists, join\n",
    "from os import mkdir\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "class Crypto_logger_base(ABC):\n",
    "    def __init__(self, interval='15s', delay=4.7, buffer_size=3000, directory='crypto_logs', \n",
    "                 log_name='crypto_log', raw=False):\n",
    "        \"\"\"\n",
    "        :param interval: OHLCV interval to log. Default is 15 seconds.\n",
    "        :param delay: delay between Binance API requests. Minimum calculated was 4.7 seconds.\n",
    "        :param buffer_size: buffer size to avoid crashing on memory accesses.\n",
    "        :param directory: the directory where to output the logs.\n",
    "        :param log_name: name of the log file.\n",
    "        :param raw: whether the log dumps raw (instantaneous) or OHLCV data.\n",
    "        \"\"\"\n",
    "        self.interval = interval\n",
    "        self.delay = delay\n",
    "        self.buffer_size = buffer_size\n",
    "        self.directory = directory\n",
    "        self.raw = raw\n",
    "\n",
    "        self.log_name = join(self.directory, log_name + '.txt')\n",
    "        self.log_screened_name = join(self.directory, log_name + '_screened.txt')\n",
    "\n",
    "        if not exists(self.directory):\n",
    "            mkdir(self.directory)\n",
    "\n",
    "    #self.get_from_file(log_name=self.log_name, from_raw=False)\n",
    "    #self.get_from_file(log_name=self.input_log_name, from_raw=self.load_from_ohlcv)\n",
    "    def get_from_file(self, log_name, from_raw=False):\n",
    "        if from_raw:\n",
    "            dataset = pd.read_csv(log_name, header=0, index_col=0)\n",
    "        else:\n",
    "            dataset = pd.read_csv(log_name, header=[0, 1], index_col=0)\n",
    "        dataset.index = pd.DatetimeIndex(dataset.index)\n",
    "        return dataset.sort_index(axis='index')\n",
    "\n",
    "    @abstractmethod\n",
    "    def get(self, **kwargs):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    @abstractmethod\n",
    "    def screen(self, **kwargs):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def put(self, dataset):\n",
    "        dataset = dataset.copy().reset_index()\n",
    "        if self.raw:\n",
    "            dataset = dataset.drop_duplicates(subset=['symbol', 'count'], \n",
    "                                              keep='first', ignore_index=True)\n",
    "        else:\n",
    "            dataset = dataset.drop_duplicates(keep='last', ignore_index=True)\n",
    "\n",
    "        if 'date' in dataset.columns:\n",
    "            min_index_int = dataset[dataset['date'] == self.min_index].index[0]\n",
    "            dataset = dataset.set_index('date')\n",
    "        if not self.raw:\n",
    "            dataset = resample(dataset, self.interval)\n",
    "        if 'date' in dataset.columns:\n",
    "            dataset = dataset.iloc[min_index_int:]\n",
    "\n",
    "        dataset = dataset.tail(self.buffer_size)\n",
    "        dataset.to_csv(self.log_name)\n",
    "        self.min_index = dataset.index[0]\n",
    "        return dataset\n",
    "\n",
    "    def start(self, append=False, roll=0):\n",
    "        \"\"\"Main logger loop.\"\"\"\n",
    "        print('Starting crypto logger.')\n",
    "\n",
    "        if exists(self.log_name) and 'output' in self.log_name:\n",
    "            self.dataset = self.get_from_file(log_name=self.log_name, from_raw=False)\n",
    "            self.dataset = self.dataset.tail(self.buffer_size)\n",
    "        else:\n",
    "            self.dataset = self.get()\n",
    "\n",
    "        self.min_index = self.dataset.index[-1]\n",
    "        self.dataset = self.put(self.dataset)\n",
    "\n",
    "        while True:\n",
    "            try:\n",
    "                dataset = pd.concat([self.dataset, self.get()], axis='index', join='outer')\n",
    "            except (KeyboardInterrupt, SystemExit):\n",
    "                print('User terminated crypto logger process.')\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "            try:\n",
    "                self.dataset = self.put(dataset)\n",
    "            except (KeyboardInterrupt, SystemExit):\n",
    "                print('Saving latest complete dataset...')\n",
    "                self.dataset = self.put(dataset)\n",
    "                print('User terminated crypto logger process.')\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "            try:\n",
    "                if exists(self.log_screened_name):\n",
    "                    dataset_screened_old = \\\n",
    "                        pd.read_csv(self.log_screened_name, index_col=0, header=0)\n",
    "                else:\n",
    "                    dataset_screened_old = None\n",
    "                dataset_screened = self.screen(self.dataset)\n",
    "                if dataset_screened is not None:\n",
    "                    if roll != 0:\n",
    "                        if append and exists(self.log_screened_name):\n",
    "                            dataset_screened = \\\n",
    "                                pd.concat([dataset_screened_old, dataset_screened], axis='index')\n",
    "                            dataset_screened = \\\n",
    "                                dataset_screened.drop_duplicates(subset=['symbol'], keep='last')\n",
    "                        dataset_screened = dataset_screened.tail(roll)\n",
    "                        dataset_screened.to_csv(self.log_screened_name)\n",
    "                    elif append:\n",
    "                        dataset_screened.to_csv(self.log_screened_name, mode='a')\n",
    "                    else:\n",
    "                        dataset_screened.to_csv(self.log_screened_name)\n",
    "            except (KeyboardInterrupt, SystemExit):\n",
    "                print('User terminated crypto logger process.')\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "            sleep(self.delay)\n",
    "        print('Crypto logger process done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# File:        cryptocurrency/crypto_logger_input.py\n",
    "# By:          Samuel Duclos\n",
    "# For          Myself\n",
    "# Description: Simple Binance logger circular buffered for N time precision.\n",
    "\n",
    "# Library imports.\n",
    "#from cryptocurrency.crypto_logger_base import Crypto_logger_base\n",
    "from cryptocurrency.authentication import Cryptocurrency_authenticator\n",
    "from cryptocurrency.exchange import Cryptocurrency_exchange\n",
    "from cryptocurrency.conversion import get_timezone_offset_in_seconds\n",
    "from cryptocurrency.conversion_table import get_conversion_table, get_tradable_tickers_info\n",
    "from os import mkdir\n",
    "from os.path import exists, join\n",
    "\n",
    "import datetime\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "class Crypto_logger_input(Crypto_logger_base):\n",
    "    def __init__(self, delay=4.7, interval='15s', buffer_size=3000, \n",
    "                 price_percent=5.0, volume_percent=0.0, as_pair=False):\n",
    "        \"\"\"\n",
    "        :param interval: OHLCV interval to log. Default is 15 seconds.\n",
    "        :param delay: delay between Binance API requests. Minimum calculated was 4.7 seconds.\n",
    "        :param buffer_size: buffer size to avoid crashing on memory accesses.\n",
    "        :param price_percent: price move percent.\n",
    "        :param volume_percent: volume move percent.\n",
    "        \"\"\"\n",
    "        self.resample = None\n",
    "        self.price_percent = price_percent\n",
    "        self.volume_percent = volume_percent\n",
    "        self.as_pair = as_pair\n",
    "        super().__init__(interval=interval, delay=delay, buffer_size=buffer_size, \n",
    "                         directory='crypto_logs', log_name='crypto_input_log_' + interval, \n",
    "                         raw=True)\n",
    "\n",
    "        authenticator = Cryptocurrency_authenticator(use_keys=False, testnet=False)\n",
    "        self.client = authenticator.spot_client\n",
    "\n",
    "        exchange = Cryptocurrency_exchange(client=self.client, directory=self.directory)\n",
    "        self.exchange_info = exchange.info\n",
    "\n",
    "        self.offset_s = get_timezone_offset_in_seconds()\n",
    "\n",
    "    def filter_movers(self, dataset, count=1000, price_percent=5.0, volume_percent=0.0):\n",
    "        dataset = dataset.reset_index()\n",
    "        dataset[['price_change_percent', 'rolling_quote_volume']] = \\\n",
    "            dataset[['price_change_percent', 'rolling_quote_volume']].astype(float)\n",
    "        dataset['last_price_move'] = dataset['price_change_percent'].copy()\n",
    "        dataset['last_volume_move'] = dataset['rolling_quote_volume'].copy()\n",
    "        movers = dataset.groupby(['symbol'])\n",
    "        dataset = dataset.drop(columns=['last_price_move', 'last_volume_move'])\n",
    "        price_movers = movers['last_price_move']\n",
    "        volume_movers = movers['last_volume_move']\n",
    "        price_movers = price_movers.agg(lambda x: x.diff(1).abs().iloc[-1])\n",
    "        volume_movers = volume_movers.agg(lambda x: (100 * x.pct_change(1)).iloc[-1])\n",
    "        price_movers = price_movers.sort_values(ascending=False)\n",
    "        volume_movers = volume_movers.sort_values(ascending=False)\n",
    "        price_movers = price_movers[price_movers > 0.0]\n",
    "        price_movers = price_movers.to_frame(name='last_price_move')\n",
    "        volume_movers = volume_movers.to_frame(name='last_volume_move')\n",
    "        movers = pd.concat([price_movers, volume_movers], axis='columns')\n",
    "        movers = movers.reset_index()\n",
    "        price_movers_mask = movers['last_price_move'] > price_percent\n",
    "        volume_movers_mask = movers['last_volume_move'] > volume_percent\n",
    "        movers = movers[price_movers_mask & volume_movers_mask]\n",
    "        movers = movers.sort_values(by=['last_volume_move', 'last_price_move'], ascending=False)\n",
    "        movers = movers.tail(count).reset_index(drop=True)\n",
    "        return dataset.merge(right=movers, how='right', on=['symbol']).set_index('date')\n",
    "\n",
    "    def screen(self, dataset):\n",
    "        dataset = get_tradable_tickers_info(dataset, as_pair=self.as_pair)\n",
    "        dataset = self.filter_movers(dataset, count=1000, \n",
    "                                     price_percent=self.price_percent, \n",
    "                                     volume_percent=self.volume_percent)\n",
    "        return dataset.drop_duplicates(subset=['symbol', 'count'], keep='last')\n",
    "\n",
    "    def prepare_downsampling(self, dataset):\n",
    "        dataset['close_time'] /= 1000\n",
    "        dataset['close_time'] = \\\n",
    "            dataset['close_time'].apply(datetime.datetime.fromtimestamp)\n",
    "        dataset['date'] = pd.DatetimeIndex(dataset['close_time']).round(self.interval)\n",
    "        return dataset.set_index('date').sort_index()\n",
    "\n",
    "    def get(self):\n",
    "        \"\"\"Get all pairs data from Binance API.\"\"\"\n",
    "        dataset = get_conversion_table(self.client, self.exchange_info, offset_s=self.offset_s, \n",
    "                                       as_pair=self.as_pair, dump_raw=False)\n",
    "        self.conversion_table = dataset.copy()\n",
    "        #self.conversion_table.to_csv('crypto_logs/conversion_table.txt')\n",
    "        return self.prepare_downsampling(self.conversion_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# File:        crypto_logger_input_1min.py\n",
    "# By:          Samuel Duclos\n",
    "# For          Myself\n",
    "# Description: Simple Binance logger output for the 1 minute interval.\n",
    "\n",
    "# Library imports.\n",
    "#from cryptocurrency.crypto_logger_input import Crypto_logger_input\n",
    "\n",
    "crypto_logger_input_1min = Crypto_logger_input(delay=12, interval='15s', buffer_size=3000, \n",
    "                                               price_percent=1.0, volume_percent=1.0, \n",
    "                                               as_pair=True)\n",
    "crypto_logger_input_1min.start(append=True, roll=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "crypto_input_log_1min = 'crypto_logs/crypto_input_log_1min.txt'\n",
    "df = pd.read_csv(crypto_input_log_1min, header=0, index_col=0)\n",
    "df.index = pd.to_datetime(df.index, utc=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "crypto_input_log_15s = 'crypto_logs/crypto_input_log_15s.txt'\n",
    "df = pd.read_csv(crypto_input_log_15s, header=0, index_col=0)\n",
    "df.index = pd.to_datetime(df.index)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "crypto_exchange_info = 'crypto_logs/crypto_exchange_info.txt'\n",
    "exchange_info = pd.read_csv(crypto_exchange_info, header=0, index_col=0)\n",
    "exchange_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cryptocurrency.authentication import Cryptocurrency_authenticator\n",
    "from cryptocurrency.conversion_table import get_conversion_table, get_new_tickers\n",
    "from cryptocurrency.exchange import Cryptocurrency_exchange\n",
    "from cryptocurrency.conversion import convert_price\n",
    "\n",
    "authenticator = Cryptocurrency_authenticator(use_keys=False, testnet=False)\n",
    "client = authenticator.spot_client\n",
    "exchange = Cryptocurrency_exchange(client=client, directory='crypto_logs')\n",
    "exchange_info = exchange.info\n",
    "conversion_table = get_conversion_table(client=client, exchange_info=exchange_info)\n",
    "#assets = get_new_tickers(conversion_table=conversion_table)\n",
    "\n",
    "symbol = 'BTCUSDT'\n",
    "#original_size = exchange_info[exchange_info['symbol'] == symbol]['lastPrice']\n",
    "quantity = df[df['symbol'] == symbol]['close'].iat[-1]\n",
    "asset = exchange_info[exchange_info['symbol'] == symbol]['baseAsset'].iat[-1]\n",
    "\n",
    "usdt_price = convert_price(size=1, from_asset=asset, to_asset='USDT', \n",
    "                           exchange_info=exchange_info, \n",
    "                           conversion_table=conversion_table, priority='accuracy')\n",
    "usdt_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['symbol', 'lastPrice', 'volume', 'bidPrice', 'bidQty', 'askPrice', 'askQty']]\n",
    "df = df.rename(columns={'lastPrice': 'close'})\n",
    "df = df.pivot_table(index=['date'], columns=['symbol'], \n",
    "                    values=['close', 'volume', 'bidPrice', 'bidQty', 'askPrice', 'askQty'], \n",
    "                    aggfunc={'close': ['first', 'max', 'min', 'last'], \n",
    "                             'volume': 'last', \n",
    "                             'bidPrice': ['first', 'max', 'min', 'last'], \n",
    "                             'bidQty': 'sum', \n",
    "                             'askPrice': ['first', 'max', 'min', 'last'], \n",
    "                             'askQty': 'sum'})\n",
    "df['volume'] = df['volume'].fillna(method='pad').fillna(0).diff(1)\n",
    "df['bidQty']['sum'] = df['bidQty']['sum'].fillna(method='pad').fillna(0).diff(1)\n",
    "df['askQty']['sum'] = df['askQty']['sum'].fillna(method='pad').fillna(0).diff(1)\n",
    "df.columns = pd.MultiIndex.from_tuples([('_'.join(col[:2]), col[2]) for col in df.columns.values])\n",
    "df = df.rename(columns={'close_first': 'open', \n",
    "                        'close_max': 'high', \n",
    "                        'close_min': 'low', \n",
    "                        'close_last': 'close', \n",
    "                        'volume_last': 'volume', \n",
    "                        'bidPrice_first': 'bid_open', \n",
    "                        'bidPrice_max': 'bid_high', \n",
    "                        'bidPrice_min': 'bid_low', \n",
    "                        'bidPrice_last': 'bid_close', \n",
    "                        'bidQty_sum': 'bid_volume', \n",
    "                        'askPrice_first': 'ask_open', \n",
    "                        'askPrice_max': 'ask_high', \n",
    "                        'askPrice_min': 'ask_low', \n",
    "                        'askPrice_last': 'ask_close', \n",
    "                        'askQty_sum': 'ask_volume'}, \n",
    "               level=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.columns.get_level_values(1).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_from_raw(df):\n",
    "    df = df[['symbol', 'lastPrice', 'volume', 'quoteVolume']]\n",
    "    df = df.rename(columns={'lastPrice': 'close', \n",
    "                            'volume': 'rolling_base_volume', \n",
    "                            'quoteVolume': 'rolling_quote_volume'})\n",
    "    df = df.pivot_table(index=['date'], columns=['symbol'], \n",
    "                        values=['close', 'rolling_base_volume', \n",
    "                                'rolling_quote_volume'], \n",
    "                        aggfunc={'close': ['first', 'max', 'min', 'last'], \n",
    "                                 'rolling_base_volume': 'max', \n",
    "                                 'rolling_quote_volume': 'max'})\n",
    "    df.columns = pd.MultiIndex.from_tuples([('_'.join(col[:2]), col[2]) for col in df.columns.values], \n",
    "                                           names=(None, 'symbol'))\n",
    "    df = df.rename(columns={'close_first': 'open', \n",
    "                            'close_max': 'high', \n",
    "                            'close_min': 'low', \n",
    "                            'close_last': 'close', \n",
    "                            'rolling_base_volume_max': 'rolling_base_volume', \n",
    "                            'rolling_quote_volume_max': 'rolling_quote_volume'}, \n",
    "                   level=0)\n",
    "    df['rolling_base_volume'] = df['rolling_base_volume'].fillna(method='pad')\n",
    "    df['rolling_base_volume'].iloc[0] = 0\n",
    "    df['rolling_quote_volume'] = df['rolling_quote_volume'].fillna(method='pad')\n",
    "    df['rolling_quote_volume'].iloc[0] = 0\n",
    "    df = df.sort_index().iloc[1:]\n",
    "    df.columns = df.columns.swaplevel(0, 1)\n",
    "    return df\n",
    "\n",
    "df2 = resample_from_raw(df)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[(df2['NEBLBUSD']['volume'].diff() < 0)]['NEBLBUSD']['volume']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2.columns = df2.columns.swaplevel(0, 1)\n",
    "(~((df2[df2['volume'] > 0]['volume']).isna())).any().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[(df2['volume'] > 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%rm -rf crypto_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyO4csgmdyxBlfVzNgUhkI0X",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "crypto_bot",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
