{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jKtLwsCCqsmH"
   },
   "source": [
    "Cryptocurrency trading bot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# File:        cryptocurrency/crypto_logger_output.py\n",
    "# By:          Samuel Duclos\n",
    "# For          Myself\n",
    "# Description: Simple Binance logger output for arbitrary intervals.\n",
    "\n",
    "\n",
    "# Library imports.\n",
    "from cryptocurrency.crypto_logger_base import Crypto_logger_base\n",
    "from cryptocurrency.renko import get_renko_trigger\n",
    "from os import mkdir\n",
    "from os.path import exists, join\n",
    "from sys import float_info as sflt\n",
    "from numpy import log\n",
    "from pandas_ta.utils._core import signed_series, recent_minimum_index\n",
    "\n",
    "import datetime\n",
    "import pandas_ta as ta\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "class Crypto_logger_output(Crypto_logger_base):\n",
    "    def __init__(self, delay=6, interval_input='15s', interval='15s', buffer_size=100, \n",
    "                 input_log_name='input', second_screener=False):\n",
    "        \"\"\"\n",
    "        :param delay: delay between Binance API requests. Minimum calculated was 5 seconds.\n",
    "        :param interval_input: OHLCV interval from input log. Default is 15 seconds.\n",
    "        :param interval: OHLCV interval to log. Default is 15 seconds.\n",
    "        :param buffer_size: buffer size to avoid crashing on low memory.\n",
    "        :param directory: the directory where to output the logs.\n",
    "        \"\"\"\n",
    "        self.data_before = pd.DataFrame()\n",
    "        input_log_name = 'crypto_' + input_log_name + '_log_'\n",
    "        self.load_from_ohlcv = interval_input != interval\n",
    "        super().__init__(interval=interval, delay=delay, buffer_size=buffer_size, \n",
    "                         directory='crypto_logs', log_name='crypto_output_log_' + interval, \n",
    "                         second_screener=second_screener, raw=False, precise=True)\n",
    "\n",
    "        #if not self.load_from_ohlcv:\n",
    "        #    self.input_log_screened_up_name = \\\n",
    "        #        join(self.directory, input_log_name + interval_input + '_screened_up.txt')\n",
    "\n",
    "        self.input_log_name = \\\n",
    "            join(self.directory, input_log_name + interval_input + '.txt')\n",
    "        self.input_log_screened_name = \\\n",
    "            join(self.directory, input_log_name + interval_input + '_screened.txt')\n",
    "\n",
    "    def get_screened(self, data_after, price_threshold=5.0, volume_threshold=300.0):\n",
    "        price_movers = pd.DataFrame()\n",
    "        volume_movers = pd.DataFrame()\n",
    "        data_before = self.data_before\n",
    "        if data_before.size != 0:\n",
    "            data_before.columns = data_before.columns.swaplevel(0, 1)\n",
    "            data_after.columns = data_after.columns.swaplevel(0, 1)\n",
    "            price_before = data_before['close'].pct_change(1)\n",
    "            price_after = data_after['close'].pct_change(1)\n",
    "            volume_before = data_before['volume'].shift(1)\n",
    "            volume_after = data_after['volume'].shift(1)\n",
    "            price_percent_change_before = \\\n",
    "                ((data_before['close'].pct_change(1) - price_before) / price_before)\n",
    "            price_percent_change_after = \\\n",
    "                ((data_after['close'].pct_change(1) - price_after) / price_after)\n",
    "            volume_percent_change_before = ((data_before['volume'] - volume_before) / volume_before)\n",
    "            volume_percent_change_after = ((data_after['volume'] - volume_after) / volume_after)\n",
    "            price_movers = \\\n",
    "                ((price_percent_change_after - price_percent_change_before) * 100) > price_threshold\n",
    "            volume_movers = \\\n",
    "                ((volume_percent_change_after - volume_percent_change_before) * 100) > volume_threshold\n",
    "            price_movers = data_after[price_movers].columns.tolist()\n",
    "            volume_movers = data_after[volume_movers].columns.tolist()\n",
    "            data_before.columns = data_before.columns.swaplevel(0, 1)\n",
    "            data_after.columns = data_after.columns.swaplevel(0, 1)\n",
    "        self.data_before = data_after\n",
    "        return price_movers + volume_movers\n",
    "\n",
    "    def screen(self, dataset):\n",
    "        def filter_in_market(function, dataset):\n",
    "            def f(x):\n",
    "                x = x.loc[:,~x.columns.duplicated()]\n",
    "                return function(x)\n",
    "            tickers_list = dataset.columns.get_level_values(0).unique().tolist()\n",
    "            return pd.Series([ticker for ticker in tickers_list if f(dataset[ticker])], dtype='str')\n",
    "\n",
    "        def get_relative_volume_levels_smoothed_thresholded(data):\n",
    "            try:\n",
    "                volume = data['volume']\n",
    "                #volume = volume.groupby(pd.Grouper(freq='D')).cumsum()\n",
    "                volume = volume.groupby(pd.Grouper(freq='24h')).cumsum()\n",
    "                #volume = volume.groupby(pd.Grouper(freq='60m')).cumsum()\n",
    "                rvol = (volume / volume.shift(1))\n",
    "                rvol = rvol.fillna(method='pad')\n",
    "                bar_up = (ticker['close'] > ticker['open'])\n",
    "                bar_up |= (ticker['close'] == ticker['open']) & (ticker['close'].diff() > 0)\n",
    "                bar_up = bar_up.astype(int)\n",
    "                bar_up = bar_up * 2 - 1\n",
    "                rvol *= bar_up\n",
    "                rvol_indicator = ta.hma(rvol, length=14, talib=True)\n",
    "                rvol_indicator = rvol_indicator.rename('relative_volume_levels_smoothed')\n",
    "                #threshold = (ta.sma(rvol, length=100, talib=True) + ta.stdev(rvol, length=100, talib=True))\n",
    "                threshold = 2\n",
    "                rvol_thresholded = (rvol_indicator > threshold).iloc[-1]\n",
    "            except:\n",
    "                rvol_thresholded = False\n",
    "            return rvol_thresholded\n",
    "\n",
    "        def get_not_square_wave_trigger_1(data):\n",
    "            return not (data.iloc[-4:]['close'].unique().size < 2)\n",
    "\n",
    "        def get_not_square_wave_trigger_2(data):\n",
    "            return not (data.iloc[-15:]['close'].unique().size < 6)\n",
    "\n",
    "        def get_not_square_wave_trigger_3(data):\n",
    "            return (data[['open', 'high', 'low', 'close']].nunique(axis='columns') > 2).tail(2).all()\n",
    "\n",
    "        def get_bullish_price_trigger(data):\n",
    "            return (data['close'] > data['high'].shift(1)).iloc[-1]\n",
    "\n",
    "        def get_positive_RSI_trigger(data):\n",
    "            RSI_6 = data.ta.rsi(length=6, talib=True)\n",
    "            RSI_12 = data.ta.rsi(length=12, talib=True)\n",
    "            RSI_24 = data.ta.rsi(length=24, talib=True)\n",
    "            data = ((RSI_6 > RSI_12) | (RSI_6 > RSI_24) | (RSI_12 > RSI_24))\n",
    "            return data.iloc[-1]\n",
    "\n",
    "        def get_positive_momentum_trigger(data):\n",
    "            KDJ = data.ta.kdj(length=5, signal=3, talib=True)\n",
    "            return ((KDJ['J_5_3'] > KDJ['D_5_3']) & (KDJ['J_5_3'] > KDJ['K_5_3'])).iloc[-1]\n",
    "\n",
    "        def get_positive_JMA_trigger(data):\n",
    "            JMA = data.ta.jma(length=7, phase=0, talib=True)\n",
    "            return (data['close'] < JMA).iloc[-1]\n",
    "\n",
    "        def get_ease_of_movement(data):\n",
    "            eom = ((data['high'] - data['low']) / (2 * data['volume'] + 1))\n",
    "            eom *= (data['high'].diff(1) + data['low'].diff(1))\n",
    "            precision = eom.abs().max()\n",
    "            if precision < 1:\n",
    "                eom *= 1 / precision\n",
    "            return eom\n",
    "\n",
    "        def get_ease_of_movement_trigger(data):\n",
    "            data[['open', 'high', 'low', 'close']] += sflt.epsilon\n",
    "            data[['volume']] += 1\n",
    "\n",
    "            log_price = log(data['close'])\n",
    "            price_trough_index = recent_minimum_index(signed_series(log_price, initial=None))\n",
    "            price_slope = ta.slope(close=log_price, length=price_trough_index, as_angle=True, \n",
    "                                   to_degrees=True, talib=True)\n",
    "\n",
    "            EOM = get_ease_of_movement(data)\n",
    "            EOM_trough_index = recent_minimum_index(signed_series(EOM, initial=None))\n",
    "            EOM_slope = ta.slope(close=EOM, length=EOM_trough_index, as_angle=True, \n",
    "                                 to_degrees=True, talib=True)\n",
    "\n",
    "            trigger = (price_slope <= EOM_slope)\n",
    "            #trigger &= (EOM_slope >= 0.25)\n",
    "            trigger &= (EOM_slope > 0.0)\n",
    "\n",
    "            #breakout_trigger = ((EOM.shift(1) < 0.0) & (EOM > 0.0))\n",
    "            #trigger |= breakout_trigger\n",
    "            return trigger.iloc[-1]\n",
    "\n",
    "        '''\n",
    "        def get_positive_PVR_trigger(data):\n",
    "            price = data['close']\n",
    "            volume = data['volume']\n",
    "            volume.iloc[-1] *= volume_multiplier\n",
    "            price_trigger = (price.diff() > 0)\n",
    "            volume_trigger = (volume.diff() > 0)\n",
    "            trigger = (price_trigger & volume_trigger)\n",
    "            return trigger.iloc[-1]\n",
    "        '''\n",
    "\n",
    "        def get_rising_volume_trigger(data):\n",
    "            return (data['rolling_base_volume'].diff(1) > 0).iloc[-1]\n",
    "\n",
    "        def get_RSI_reversal_trigger(data, rsi_length=2, upper_threshold=95, \n",
    "                                     lower_threshold=5, positive=True):\n",
    "            RSI = data.ta.rsi(length=rsi_length, talib=True)\n",
    "            RSI_prev = RSI.shift(1)\n",
    "            thresholds_bear = -((RSI_prev >= upper_threshold) & (RSI < upper_threshold)).astype(int)\n",
    "            thresholds_bull = ((RSI_prev <= lower_threshold) & (RSI > lower_threshold)).astype(int)\n",
    "            thresholds = (thresholds_bear + thresholds_bull)\n",
    "            thresholds = thresholds.replace(to_replace=0, method='pad')\n",
    "            return (thresholds == (1 if positive else -1)).iloc[-1]\n",
    "\n",
    "        def get_heikin_ashi_trigger(data):\n",
    "            def get_positive_trend_strength_trigger(data):\n",
    "                ADX = data.ta.adx(talib=True)\n",
    "                return (ADX['ADX_14'] < 0.20).iloc[-3] and (ADX['ADX_14'] > 0.20).iloc[-2]\n",
    "\n",
    "            def get_not_negative_trend_strength_trigger(data):\n",
    "                ADX = data.ta.adx(length=14, lensig=8, talib=True)\n",
    "                return ((ADX['DMP_14'] > ADX['DMN_14']) and (ADX['ADX_14'] > 0.30)).iloc[-1]\n",
    "\n",
    "            def get_not_negative_rebound_trigger(data):\n",
    "                CCI = data.ta.cci(length=22, talib=True)\n",
    "                MFI = data.ta.mfi(length=11, talib=True)\n",
    "                return ((CCI > 0) or (MFI > 20)).iloc[-1]\n",
    "\n",
    "            def get_positive_choppiness_trigger(data):\n",
    "                CHOP = data.ta.chop(talib=True)\n",
    "                return CHOP.iloc[-1] < 38.2\n",
    "\n",
    "            def get_positive_phase_trigger(data):\n",
    "                MACD = data.ta.macd(talib=True)\n",
    "                histogram = MACD['MACDs_12_26_9'] - MACD['MACD_12_26_9']\n",
    "                return ((histogram.iloc[-1] > histogram.iloc[-2]) or \\\n",
    "                        (MACD['MACD_12_26_9'].iloc[-1] > MACD['MACDs_12_26_9'].iloc[-1]))\n",
    "\n",
    "            def get_positive_RSI_trigger(data):\n",
    "                RSI_5 = data.ta.rsi(length=5, talib=True)\n",
    "                return ((RSI_5 >= 60) & (RSI_5 <= 65)).iloc[-1]\n",
    "\n",
    "            def get_negative_PVR_trigger(data):\n",
    "                price_trigger = (data['close'].iloc[-1] < data['close'].iloc[-2])\n",
    "                volume_trigger = (data['volume'].iloc[-1] > data['volume'].iloc[-2])\n",
    "                return price_trigger and volume_trigger\n",
    "\n",
    "            def get_buy_trigger(data):\n",
    "                return get_not_negative_rebound_trigger(data) and \\\n",
    "                        (get_positive_choppiness_trigger(data) or \\\n",
    "                        get_positive_trend_strength_trigger(data))\n",
    "\n",
    "            def get_sell_trigger(data):\n",
    "                return (((not get_positive_choppiness_trigger(data)) or \\\n",
    "                         get_negative_trend_strength_trigger(data) or \\\n",
    "                         (not get_positive_phase_trigger(data))) or \\\n",
    "                        get_not_negative_rebound_trigger(data))\n",
    "\n",
    "            heikin_ashi = data.ta.ha(talib=True)\n",
    "            heikin_ashi_dataset_1 = heikin_ashi.rename(columns={'HA_open': 'open', \n",
    "                                                                'HA_high': 'high', \n",
    "                                                                'HA_low': 'low', \n",
    "                                                                'HA_close': 'close'})\n",
    "            #heikin_ashi = heikin_ashi_dataset_1.ta.ha(talib=True)\n",
    "            #heikin_ashi_dataset_2 = heikin_ashi.rename(columns={'HA_open': 'open', \n",
    "            #                                                    'HA_high': 'high', \n",
    "            #                                                    'HA_low': 'low', \n",
    "            #                                                    'HA_close': 'close'})\n",
    "            #heikin_ashi = heikin_ashi_dataset_2.ta.ha(talib=True)\n",
    "            #heikin_ashi_dataset_3 = heikin_ashi.rename(columns={'HA_open': 'open', \n",
    "            #                                                    'HA_high': 'high', \n",
    "            #                                                    'HA_low': 'low', \n",
    "            #                                                    'HA_close': 'close'})\n",
    "            #if get_not_negative_rebound_trigger(heikin_ashi_dataset_1):\n",
    "            #    return True\n",
    "            return True \\\n",
    "                if get_positive_phase_trigger(heikin_ashi_dataset_1) \\\n",
    "                else (get_not_negative_rebound_trigger(heikin_ashi_dataset_1) or \\\n",
    "                      get_not_negative_trend_strength_trigger(heikin_ashi_dataset_1))\n",
    "\n",
    "        def screen_one(pair):\n",
    "            frequency = pd.tseries.frequencies.to_offset((pair.index[1:] - pair.index[:-1]).min())\n",
    "            frequency_1min = pd.tseries.frequencies.to_offset('1min')\n",
    "            frequency_30min = pd.tseries.frequencies.to_offset('30min')\n",
    "            frequency_1h = pd.tseries.frequencies.to_offset('1h')\n",
    "            if frequency < frequency_1min:\n",
    "                pair['volume'] = pair['rolling_base_volume'].copy()\n",
    "            else:\n",
    "                pair['volume'] = pair['base_volume'].copy()\n",
    "            if frequency == frequency_30min:\n",
    "                if get_not_square_wave_trigger_1(pair):\n",
    "                    if get_not_square_wave_trigger_2(pair):\n",
    "                        #if get_bullish_price_trigger(pair):\n",
    "                        #if get_heikin_ashi_trigger(pair):\n",
    "                        if get_renko_trigger(pair, compress=False, \n",
    "                                             direction_type='long', \n",
    "                                             trigger_type='simple', \n",
    "                                             method='atr', plot=False):\n",
    "                            return True\n",
    "            elif frequency == frequency_1h:\n",
    "                if get_relative_volume_levels_smoothed_thresholded(pair):\n",
    "                    return True\n",
    "            else:\n",
    "                if get_not_square_wave_trigger_1(pair):\n",
    "                    if get_not_square_wave_trigger_2(pair):\n",
    "                        if frequency < frequency_1min:\n",
    "                            return True \n",
    "                        else:\n",
    "                            if get_rising_volume_trigger(pair):\n",
    "                                if get_heikin_ashi_trigger(pair):\n",
    "                                    return True\n",
    "            return False\n",
    "\n",
    "        #if not self.load_from_ohlcv:\n",
    "        #    if exists(self.input_log_screened_up_name):\n",
    "        #        input_filtered_up = pd.read_csv(self.input_log_screened_up_name, header=0, index_col=None)\n",
    "        if exists(self.input_log_screened_name):\n",
    "            input_filtered = pd.read_csv(self.input_log_screened_name, header=0, index_col=0)\n",
    "            input_filter = set(input_filtered['symbol'].tolist())\n",
    "            #if not self.load_from_ohlcv:\n",
    "            #    input_filter = input_filter & set(input_filtered_up['symbol'].tolist())\n",
    "            old_columns = set(dataset.columns.get_level_values(0).tolist())\n",
    "            new_columns = list(input_filter & old_columns)\n",
    "            dataset = dataset[new_columns]\n",
    "\n",
    "            #assets = self.get_screened(dataset, price_threshold=1.0, volume_threshold=1.0)\n",
    "            #input_filtered_movers = input_filtered[input_filtered['symbol'].isin(assets)]\n",
    "            #input_filtered_movers.to_csv(self.input_log_screened_name, mode='a')\n",
    "            assets = filter_in_market(screen_one, dataset)\n",
    "            return input_filtered[input_filtered['symbol'].isin(assets)]\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def screen_(self, dataset):\n",
    "        return dataset\n",
    "\n",
    "    def resample_from_raw(self, df):\n",
    "        df = df[['symbol', 'lastPrice', 'volume', 'quoteVolume']]\n",
    "        df = df.rename(columns={'lastPrice': 'close', \n",
    "                                'volume': 'rolling_base_volume', \n",
    "                                'quoteVolume': 'rolling_quote_volume'})\n",
    "        df = df.pivot_table(index=['date'], columns=['symbol'], \n",
    "                            values=['close', 'rolling_base_volume', \n",
    "                                    'rolling_quote_volume'], \n",
    "                            aggfunc={'close': ['first', 'max', 'min', 'last'], \n",
    "                                     'rolling_base_volume': 'max', \n",
    "                                     'rolling_quote_volume': 'max'})\n",
    "        df.columns = pd.MultiIndex.from_tuples([('_'.join(col[:2]), col[2]) for col in df.columns.values], \n",
    "                                               names=(None, 'symbol'))\n",
    "        df = df.rename(columns={'close_first': 'open', \n",
    "                                'close_max': 'high', \n",
    "                                'close_min': 'low', \n",
    "                                'close_last': 'close', \n",
    "                                'rolling_base_volume_max': 'rolling_base_volume', \n",
    "                                'rolling_quote_volume_max': 'rolling_quote_volume'}, \n",
    "                       level=0)\n",
    "        df['rolling_base_volume'] = df['rolling_base_volume'].fillna(method='pad')\n",
    "        df['rolling_base_volume'].iloc[0] = 0\n",
    "        df['rolling_quote_volume'] = df['rolling_quote_volume'].fillna(method='pad')\n",
    "        df['rolling_quote_volume'].iloc[0] = 0\n",
    "        df = df.sort_index().iloc[1:]\n",
    "        df.columns = df.columns.swaplevel(0, 1)\n",
    "        return df\n",
    "\n",
    "    def get(self):\n",
    "        if self.load_from_ohlcv:\n",
    "            dataset = pd.read_csv(self.input_log_name, header=[0, 1], index_col=0)\n",
    "        else:\n",
    "            dataset = pd.read_csv(self.input_log_name, header=0, index_col=0)\n",
    "            dataset = self.resample_from_raw(dataset)\n",
    "        return dataset.sort_index().tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# File:        cryptocurrency/crypto_logger_input.py\n",
    "# By:          Samuel Duclos\n",
    "# For          Myself\n",
    "# Description: Simple Binance logger circular buffered for N time precision.\n",
    "\n",
    "# Library imports.\n",
    "from cryptocurrency.crypto_logger_base import Crypto_logger_base\n",
    "from cryptocurrency.authentication import Cryptocurrency_authenticator\n",
    "from cryptocurrency.exchange import Cryptocurrency_exchange\n",
    "from cryptocurrency.conversion import get_base_asset_from_pair, get_quote_asset_from_pair\n",
    "from os import mkdir\n",
    "from os.path import exists, join\n",
    "\n",
    "import datetime\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "class Crypto_logger_input(Crypto_logger_base):\n",
    "    def __init__(self, client=None, delay=4.7, interval='1min', buffer_size=20000, \n",
    "                 price_percent=5.0, volume_percent=1.0):\n",
    "        \"\"\"\n",
    "        :param interval: OHLCV interval to log. Default is 1 minute.\n",
    "        :param delay: delay between Binance API requests. Minimum calculated was 5 seconds.\n",
    "        :param buffer_size: buffer size to avoid crashing on low memory.\n",
    "        :param directory: the directory where to output the logs.\n",
    "        \"\"\"\n",
    "        self.resample = None\n",
    "        self.price_percent = price_percent\n",
    "        self.volume_percent = volume_percent\n",
    "        super().__init__(interval=interval, delay=delay, buffer_size=buffer_size, \n",
    "                         directory='crypto_logs', log_name='crypto_input_log_' + interval, \n",
    "                         second_screener=False, raw=True, precise=False)\n",
    "\n",
    "        #self.log_screened_up_name = self.log_name.replace('.txt', '') + '_screened_up.txt'\n",
    "\n",
    "        authenticator = Cryptocurrency_authenticator(use_keys=False, testnet=False)\n",
    "        self.client = authenticator.spot_client\n",
    "\n",
    "        exchange = Cryptocurrency_exchange(client=self.client, directory=self.directory)\n",
    "        self.exchange_info = exchange.info\n",
    "\n",
    "    def filter_movers(self, dataset, count=1000, price_percent=5.0, volume_percent=1.0):\n",
    "        dataset = dataset.reset_index()\n",
    "        dataset[['priceChangePercent', 'rolling_quote_volume']] = \\\n",
    "            dataset[['priceChangePercent', 'rolling_quote_volume']].astype(float)\n",
    "        dataset['last_price_move'] = dataset['priceChangePercent'].copy()\n",
    "        dataset['last_volume_move'] = dataset['rolling_quote_volume'].copy()\n",
    "        movers = dataset.groupby(['symbol'])\n",
    "        dataset = dataset.drop(columns=['last_price_move', 'last_volume_move'])\n",
    "        price_movers = movers['last_price_move']\n",
    "        volume_movers = movers['last_volume_move']\n",
    "        price_movers = price_movers.agg(lambda x: x.diff(1).abs().iloc[-1])\n",
    "        volume_movers = volume_movers.agg(lambda x: (100 * x.pct_change(1)).iloc[-1])\n",
    "        price_movers = price_movers.sort_values(ascending=False)\n",
    "        volume_movers = volume_movers.sort_values(ascending=False)\n",
    "        price_movers = price_movers[price_movers > 0.0]\n",
    "        #price_movers_int = price_movers.copy().dropna().astype(int)\n",
    "        #price_movers_int = price_movers_int[price_movers_int >= 0]\n",
    "        price_movers = price_movers.to_frame(name='last_price_move')\n",
    "        volume_movers = volume_movers.to_frame(name='last_volume_move')\n",
    "        #price_movers_int.to_csv(self.log_screened_up_name)\n",
    "        movers = pd.concat([price_movers, volume_movers], axis='columns')\n",
    "        movers = movers.reset_index()\n",
    "        price_movers_mask = movers['last_price_move'] > price_percent\n",
    "        volume_movers_mask = movers['last_volume_move'] > volume_percent\n",
    "        movers = movers[price_movers_mask & volume_movers_mask]\n",
    "        movers = movers.sort_values(by=['last_volume_move', 'last_price_move'], ascending=False)\n",
    "        movers = movers.tail(count).reset_index(drop=True)\n",
    "        return dataset.merge(right=movers, how='right', on=['symbol']).set_index('date')\n",
    "\n",
    "    def get_highest_daily_volume_pair_associated_with_base_asset(self, base_asset):\n",
    "        pairs = self.exchange_info[self.exchange_info['baseAsset'] == base_asset]['symbol'].tolist()\n",
    "        filtered_pairs = self.conversion_table[self.conversion_table['symbol'].isin(pairs)]\n",
    "        filtered_pairs = filtered_pairs.sort_values(by=['rolling_quote_volume'], ascending=False)\n",
    "        try:\n",
    "            filtered_pairs = filtered_pairs['symbol'].iloc[0]\n",
    "        except IndexError:\n",
    "            filtered_pairs = None\n",
    "        return filtered_pairs\n",
    "\n",
    "    def screen(self, dataset):\n",
    "        dataset = dataset[['symbol', 'lastPrice', 'priceChangePercent', \n",
    "                           'bidPrice', 'askPrice', 'bidQty', 'askQty', \n",
    "                           'volume', 'quoteVolume', 'count']]\n",
    "        dataset[['priceChangePercent', 'lastPrice', 'bidPrice', 'askPrice', \n",
    "                 'bidQty', 'askQty', 'volume', 'quoteVolume', 'count']] = \\\n",
    "            dataset[['priceChangePercent', 'lastPrice', 'bidPrice', 'askPrice', \n",
    "                     'bidQty', 'askQty', 'volume', 'quoteVolume', 'count']].astype(float)\n",
    "        dataset = dataset.rename(columns={'volume': 'rolling_base_volume', \n",
    "                                          'quoteVolume': 'rolling_quote_volume'})\n",
    "        #dataset = dataset[dataset['quote_volume'] > 50000]\n",
    "        dataset['bidAskChangePercent'] = \\\n",
    "            ((dataset['askPrice'] - dataset['bidPrice']) / dataset['askPrice'])\n",
    "        dataset['bidAskQtyPercent'] = \\\n",
    "            (dataset['bidQty'] / (dataset['bidQty'] + dataset['askQty']))\n",
    "        dataset[['bidAskChangePercent', 'bidAskQtyPercent']] *= 100\n",
    "        dataset = dataset.dropna()\n",
    "        dataset = dataset[dataset['bidAskChangePercent'] < 0.8]\n",
    "        #dataset = dataset[dataset['bidAskQtyPercent'] > 100.0]\n",
    "        dataset = self.filter_movers(dataset, count=1000, price_percent=self.price_percent, \n",
    "                                     volume_percent=self.volume_percent)\n",
    "        dataset = dataset.drop_duplicates(subset=['symbol', 'count'], keep='last')\n",
    "        dataset['base_asset'] = dataset['symbol'].apply(lambda x: get_base_asset_from_pair(x, exchange_info=self.exchange_info))\n",
    "        dataset['quote_asset'] = dataset['symbol'].apply(lambda x: get_quote_asset_from_pair(x, exchange_info=self.exchange_info))\n",
    "        #dataset['symbol_2'] = dataset['base_asset'].apply(lambda x: self.get_highest_daily_volume_pair_associated_with_base_asset(base_asset=x))\n",
    "        #dataset[dataset['symbol_2'] == None]['symbol_2'] = dataset[dataset['symbol_2'] == None]['symbol']\n",
    "        #dataset['symbol'] = dataset['symbol_2'].copy()\n",
    "        #dataset = dataset.drop(columns=['symbol_2'])\n",
    "        return dataset\n",
    "\n",
    "    def prepare_downsampling(self, dataset):\n",
    "        dataset['closeTime'] /= 1000\n",
    "        dataset['openTime'] /= 1000\n",
    "        dataset['openTime'] = \\\n",
    "            dataset['openTime'].apply(datetime.datetime.fromtimestamp)\n",
    "        dataset['closeTime'] = \\\n",
    "            dataset['closeTime'].apply(datetime.datetime.fromtimestamp)\n",
    "        dataset['date'] = pd.DatetimeIndex(dataset['closeTime']).round(self.interval)\n",
    "        return dataset.set_index('date').sort_index()\n",
    "\n",
    "    def get(self):\n",
    "        \"\"\"Get all pairs data from Binance API.\"\"\"\n",
    "        dataset = pd.DataFrame(self.client.get_ticker())\n",
    "        self.conversion_table = dataset.copy()\n",
    "        self.conversion_table.to_csv(self.log_name.replace('.txt', '') + '_conversion_table.txt')\n",
    "        return self.prepare_downsampling(self.conversion_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# File:        crypto_logger_input_1min.py\n",
    "# By:          Samuel Duclos\n",
    "# For          Myself\n",
    "# Description: Simple Binance logger output for the 1 minute interval.\n",
    "\n",
    "# Library imports.\n",
    "#from cryptocurrency.crypto_logger_input import Crypto_logger_input\n",
    "\n",
    "crypto_logger_input_1min = Crypto_logger_input(delay=12, interval='1min', buffer_size=20000, \n",
    "                                               price_percent=1.0, volume_percent=1.0)\n",
    "crypto_logger_input_1min.start(append=True, roll=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "crypto_input_log_1min = 'crypto_logs/crypto_input_log_1min.txt'\n",
    "df = pd.read_csv(crypto_input_log_1min, header=0, index_col=0)\n",
    "df.index = pd.to_datetime(df.index, utc=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "crypto_input_log_15s = 'crypto_logs/crypto_input_log_15s.txt'\n",
    "df = pd.read_csv(crypto_input_log_15s, header=0, index_col=0)\n",
    "df.index = pd.to_datetime(df.index)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['symbol', 'lastPrice', 'volume', 'bidPrice', 'bidQty', 'askPrice', 'askQty']]\n",
    "df = df.rename(columns={'lastPrice': 'close'})\n",
    "df = df.pivot_table(index=['date'], columns=['symbol'], \n",
    "                    values=['close', 'volume', 'bidPrice', 'bidQty', 'askPrice', 'askQty'], \n",
    "                    aggfunc={'close': ['first', 'max', 'min', 'last'], \n",
    "                             'volume': 'last', \n",
    "                             'bidPrice': ['first', 'max', 'min', 'last'], \n",
    "                             'bidQty': 'sum', \n",
    "                             'askPrice': ['first', 'max', 'min', 'last'], \n",
    "                             'askQty': 'sum'})\n",
    "df['volume'] = df['volume'].fillna(method='pad').fillna(0).diff(1)\n",
    "df['bidQty']['sum'] = df['bidQty']['sum'].fillna(method='pad').fillna(0).diff(1)\n",
    "df['askQty']['sum'] = df['askQty']['sum'].fillna(method='pad').fillna(0).diff(1)\n",
    "df.columns = pd.MultiIndex.from_tuples([('_'.join(col[:2]), col[2]) for col in df.columns.values])\n",
    "df = df.rename(columns={'close_first': 'open', \n",
    "                        'close_max': 'high', \n",
    "                        'close_min': 'low', \n",
    "                        'close_last': 'close', \n",
    "                        'volume_last': 'volume', \n",
    "                        'bidPrice_first': 'bid_open', \n",
    "                        'bidPrice_max': 'bid_high', \n",
    "                        'bidPrice_min': 'bid_low', \n",
    "                        'bidPrice_last': 'bid_close', \n",
    "                        'bidQty_sum': 'bid_volume', \n",
    "                        'askPrice_first': 'ask_open', \n",
    "                        'askPrice_max': 'ask_high', \n",
    "                        'askPrice_min': 'ask_low', \n",
    "                        'askPrice_last': 'ask_close', \n",
    "                        'askQty_sum': 'ask_volume'}, \n",
    "               level=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.columns.get_level_values(1).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_from_raw(df):\n",
    "    df = df[['symbol', 'lastPrice', 'volume', 'quoteVolume']]\n",
    "    df = df.rename(columns={'lastPrice': 'close', \n",
    "                            'volume': 'rolling_base_volume', \n",
    "                            'quoteVolume': 'rolling_quote_volume'})\n",
    "    df = df.pivot_table(index=['date'], columns=['symbol'], \n",
    "                        values=['close', 'rolling_base_volume', \n",
    "                                'rolling_quote_volume'], \n",
    "                        aggfunc={'close': ['first', 'max', 'min', 'last'], \n",
    "                                 'rolling_base_volume': 'max', \n",
    "                                 'rolling_quote_volume': 'max'})\n",
    "    df.columns = pd.MultiIndex.from_tuples([('_'.join(col[:2]), col[2]) for col in df.columns.values], \n",
    "                                           names=(None, 'symbol'))\n",
    "    df = df.rename(columns={'close_first': 'open', \n",
    "                            'close_max': 'high', \n",
    "                            'close_min': 'low', \n",
    "                            'close_last': 'close', \n",
    "                            'rolling_base_volume_max': 'rolling_base_volume', \n",
    "                            'rolling_quote_volume_max': 'rolling_quote_volume'}, \n",
    "                   level=0)\n",
    "    df['rolling_base_volume'] = df['rolling_base_volume'].fillna(method='pad')\n",
    "    df['rolling_base_volume'].iloc[0] = 0\n",
    "    df['rolling_quote_volume'] = df['rolling_quote_volume'].fillna(method='pad')\n",
    "    df['rolling_quote_volume'].iloc[0] = 0\n",
    "    df = df.sort_index().iloc[1:]\n",
    "    df.columns = df.columns.swaplevel(0, 1)\n",
    "    return df\n",
    "\n",
    "df2 = resample_from_raw(df)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[(df2['NEBLBUSD']['volume'].diff() < 0)]['NEBLBUSD']['volume']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2.columns = df2.columns.swaplevel(0, 1)\n",
    "(~((df2[df2['volume'] > 0]['volume']).isna())).any().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[(df2['volume'] > 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%rm -rf crypto_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyO4csgmdyxBlfVzNgUhkI0X",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "crypto_bot",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
