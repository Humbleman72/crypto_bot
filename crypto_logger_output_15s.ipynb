{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jKtLwsCCqsmH"
   },
   "source": [
    "Cryptocurrency trading bot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# File:        cryptocurrency/crypto_logger_base.py\n",
    "# By:          Samuel Duclos\n",
    "# For          Myself\n",
    "# Description: Simple Binance logger base class.\n",
    "\n",
    "# Library imports.\n",
    "from cryptocurrency.resample import resample\n",
    "from binance.client import Client\n",
    "from abc import abstractmethod, ABC\n",
    "from time import sleep, time\n",
    "from os.path import exists, join\n",
    "from os import mkdir\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "class Crypto_logger_base(ABC):\n",
    "    def __init__(self, interval='15s', delay=4.7, buffer_size=3000, directory='crypto_logs', \n",
    "                 log_name='crypto_log', raw=False):\n",
    "        \"\"\"\n",
    "        :param interval: OHLCV interval to log. Default is 15 seconds.\n",
    "        :param delay: delay between Binance API requests. Minimum calculated was 4.7 seconds.\n",
    "        :param buffer_size: buffer size to avoid crashing on memory accesses.\n",
    "        :param directory: the directory where to output the logs.\n",
    "        :param log_name: name of the log file.\n",
    "        :param raw: whether the log dumps raw (instantaneous) or OHLCV data.\n",
    "        \"\"\"\n",
    "        self.interval = interval\n",
    "        self.delay = delay\n",
    "        self.buffer_size = buffer_size\n",
    "        self.directory = directory\n",
    "        self.raw = raw\n",
    "\n",
    "        self.log_name = join(self.directory, log_name + '.txt')\n",
    "        self.log_screened_name = join(self.directory, log_name + '_screened.txt')\n",
    "\n",
    "        if not exists(self.directory):\n",
    "            mkdir(self.directory)\n",
    "\n",
    "    #self.get_from_file(log_name=self.log_name, from_raw=False)\n",
    "    #self.get_from_file(log_name=self.input_log_name, from_raw=self.load_from_ohlcv)\n",
    "    def get_from_file(self, log_name, from_raw=False):\n",
    "        if from_raw:\n",
    "            dataset = pd.read_csv(log_name, header=0, index_col=0)\n",
    "        else:\n",
    "            dataset = pd.read_csv(log_name, header=[0, 1], index_col=0)\n",
    "        dataset.index = pd.DatetimeIndex(dataset.index)\n",
    "        return dataset.sort_index(axis='index')\n",
    "\n",
    "    @abstractmethod\n",
    "    def get(self, **kwargs):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    @abstractmethod\n",
    "    def screen(self, **kwargs):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def put(self, dataset):\n",
    "        dataset = dataset.copy().reset_index()\n",
    "        if self.raw:\n",
    "            dataset = dataset.drop_duplicates(subset=['symbol', 'count'], \n",
    "                                              keep='first', ignore_index=True)\n",
    "        else:\n",
    "            dataset = dataset.drop_duplicates(keep='last', ignore_index=True)\n",
    "\n",
    "        if 'date' in dataset.columns:\n",
    "            min_index_int = dataset[dataset['date'] == self.min_index].index[0]\n",
    "            dataset = dataset.set_index('date')\n",
    "        if not self.raw:\n",
    "            dataset = resample(dataset, self.interval)\n",
    "        if 'date' in dataset.columns:\n",
    "            dataset = dataset.iloc[min_index_int:]\n",
    "\n",
    "        dataset = dataset.tail(self.buffer_size)\n",
    "        dataset.to_csv(self.log_name)\n",
    "        self.min_index = dataset.index[0]\n",
    "        return dataset\n",
    "\n",
    "    def start(self, append=False, roll=0):\n",
    "        \"\"\"Main logger loop.\"\"\"\n",
    "        print('Starting crypto logger.')\n",
    "\n",
    "        if exists(self.log_name) and 'output' in self.log_name:\n",
    "            self.dataset = self.get_from_file(log_name=self.log_name, from_raw=False)\n",
    "            self.dataset = self.dataset.tail(self.buffer_size)\n",
    "        else:\n",
    "            self.dataset = self.get()\n",
    "\n",
    "        self.min_index = self.dataset.index[-1]\n",
    "        self.dataset = self.put(self.dataset)\n",
    "\n",
    "        while True:\n",
    "            try:\n",
    "                dataset = pd.concat([self.dataset, self.get()], axis='index', join='outer')\n",
    "            except (KeyboardInterrupt, SystemExit):\n",
    "                print('User terminated crypto logger process.')\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "            try:\n",
    "                self.dataset = self.put(dataset)\n",
    "            except (KeyboardInterrupt, SystemExit):\n",
    "                print('Saving latest complete dataset...')\n",
    "                self.dataset = self.put(dataset)\n",
    "                print('User terminated crypto logger process.')\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "            try:\n",
    "                if exists(self.log_screened_name):\n",
    "                    dataset_screened_old = \\\n",
    "                        pd.read_csv(self.log_screened_name, index_col=0, header=0)\n",
    "                else:\n",
    "                    dataset_screened_old = None\n",
    "                dataset_screened = self.screen(self.dataset)\n",
    "                if dataset_screened is not None:\n",
    "                    if roll != 0:\n",
    "                        if append and exists(self.log_screened_name):\n",
    "                            dataset_screened = \\\n",
    "                                pd.concat([dataset_screened_old, dataset_screened], axis='index')\n",
    "                            dataset_screened = \\\n",
    "                                dataset_screened.drop_duplicates(subset=['symbol'], keep='last')\n",
    "                        dataset_screened = dataset_screened.tail(roll)\n",
    "                        dataset_screened.to_csv(self.log_screened_name)\n",
    "                    elif append:\n",
    "                        dataset_screened.to_csv(self.log_screened_name, mode='a')\n",
    "                    else:\n",
    "                        dataset_screened.to_csv(self.log_screened_name)\n",
    "            except (KeyboardInterrupt, SystemExit):\n",
    "                print('User terminated crypto logger process.')\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "            sleep(self.delay)\n",
    "        print('Crypto logger process done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# File:        cryptocurrency/crypto_logger_output.py\n",
    "# By:          Samuel Duclos\n",
    "# For          Myself\n",
    "# Description: Simple Binance logger output for arbitrary intervals.\n",
    "\n",
    "# Library imports.\n",
    "#from cryptocurrency.crypto_logger_base import Crypto_logger_base\n",
    "from cryptocurrency.indicators import filter_in_market, screen_one\n",
    "from os.path import exists, join\n",
    "\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "class Crypto_logger_output(Crypto_logger_base):\n",
    "    def __init__(self, delay=12, interval_input='15s', interval='15s', buffer_size=60, \n",
    "                 input_log_name='input'):\n",
    "        \"\"\"\n",
    "        :param delay: delay between logger/screener service interruptions.\n",
    "        :param interval_input: OHLCV interval from input log. Default is 15 seconds.\n",
    "        :param interval: OHLCV interval to log. Default is 15 seconds.\n",
    "        :param buffer_size: buffer size to avoid crashing on memory accesses.\n",
    "        :param input_log_name: the directory where to take the logs from.\n",
    "        \"\"\"\n",
    "        self.data_before = pd.DataFrame()\n",
    "        input_log_name = 'crypto_' + input_log_name + '_log_'\n",
    "        self.load_from_ohlcv = interval_input != interval\n",
    "        super().__init__(interval=interval, delay=delay, buffer_size=buffer_size, \n",
    "                         directory='crypto_logs', log_name='crypto_output_log_' + interval, \n",
    "                         raw=False)\n",
    "\n",
    "        self.input_log_name = \\\n",
    "            join(self.directory, input_log_name + interval_input + '.txt')\n",
    "        self.input_log_screened_name = \\\n",
    "            join(self.directory, input_log_name + interval_input + '_screened.txt')\n",
    "\n",
    "    def screen(self, dataset):\n",
    "        input_filtered = None\n",
    "        if exists(self.input_log_screened_name):\n",
    "            input_filtered = pd.read_csv(self.input_log_screened_name, header=0, index_col=0)\n",
    "            input_filter = set(input_filtered['symbol'].tolist())\n",
    "            old_columns = set(dataset.columns.get_level_values(0).tolist())\n",
    "            new_columns = list(input_filter & old_columns)\n",
    "            dataset = dataset[new_columns]\n",
    "            assets = filter_in_market(screen_one, dataset)\n",
    "            input_filtered = input_filtered[input_filtered['symbol'].isin(assets)]\n",
    "        return input_filtered\n",
    "\n",
    "    def resample_from_raw(self, df):\n",
    "        df = df[['symbol', 'close', 'rolling_base_volume', 'rolling_quote_volume']]\n",
    "        df['base_volume'] = df['rolling_base_volume'].copy()\n",
    "        df['quote_volume'] = df['rolling_quote_volume'].copy()\n",
    "        df = df.pivot_table(index=['date'], columns=['symbol'], \n",
    "                            values=['close', 'rolling_base_volume', \n",
    "                                    'rolling_quote_volume', \n",
    "                                    'base_volume', 'quote_volume'], \n",
    "                            aggfunc={'close': ['first', 'max', 'min', 'last'], \n",
    "                                     'base_volume': 'max', 'quote_volume': 'max', \n",
    "                                     'rolling_base_volume': 'max', \n",
    "                                     'rolling_quote_volume': 'max'})\n",
    "        df.columns = pd.MultiIndex.from_tuples([('_'.join(col[:2]), col[2]) \n",
    "                                                for col in df.columns.values], \n",
    "                                               names=('pair', 'symbol'))\n",
    "        df = df.rename(columns={'close_first': 'open', 'close_max': 'high', \n",
    "                                'close_min': 'low', 'close_last': 'close', \n",
    "                                'base_volume_max': 'base_volume', \n",
    "                                'quote_volume_max': 'quote_volume', \n",
    "                                'rolling_base_volume_max': 'rolling_base_volume', \n",
    "                                'rolling_quote_volume_max': 'rolling_quote_volume'}, \n",
    "                       level=0)\n",
    "        df['base_volume'] = df['base_volume'].fillna(0)\n",
    "        df['quote_volume'] = df['quote_volume'].fillna(0)\n",
    "        df['rolling_base_volume'] = df['rolling_base_volume'].fillna(method='pad').fillna(0)\n",
    "        df['rolling_quote_volume'] = df['rolling_quote_volume'].fillna(method='pad').fillna(0)\n",
    "        df = df.sort_index().iloc[1:]\n",
    "        df.columns = df.columns.swaplevel(0, 1)\n",
    "        return df\n",
    "\n",
    "    def get(self):\n",
    "        dataset = self.get_from_file(log_name=self.input_log_name, \n",
    "                                     from_raw=not self.load_from_ohlcv)\n",
    "        if not self.load_from_ohlcv:\n",
    "            dataset = self.resample_from_raw(dataset)\n",
    "        return dataset.tail(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# File:        crypto_logger_output_1min.py\n",
    "# By:          Samuel Duclos\n",
    "# For          Myself\n",
    "# Description: Simple Binance logger output for the 1 minute interval.\n",
    "\n",
    "# Library imports.\n",
    "#from cryptocurrency.crypto_logger_output import Crypto_logger_output\n",
    "\n",
    "crypto_logger_output_1min = Crypto_logger_output(delay=33, \n",
    "                                                 interval_input='15s', \n",
    "                                                 interval='15s', \n",
    "                                                 buffer_size=60, \n",
    "                                                 input_log_name='output')\n",
    "crypto_logger_output_1min.start(append=False, roll=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "input_log_name = 'crypto_logs/crypto_input_log_15s.txt'\n",
    "df = pd.read_csv(input_log_name, header=0, index_col=0)\n",
    "df.index = pd.DatetimeIndex(df.index)\n",
    "df = df.sort_index(axis='index')\n",
    "#df = crypto_logger_output_1min.resample_from_raw(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#crypto_output_log_1d = crypto_logger_output_1d.log_name\n",
    "crypto_output_log_1d = 'crypto_logs/crypto_output_log_1d.txt'\n",
    "df_1d = pd.read_csv(crypto_output_log_1d, header=[0, 1], index_col=0)\n",
    "df_1d.index = pd.DatetimeIndex(df_1d.index)\n",
    "df_1d = df_1d.sort_index(axis='index')\n",
    "df_1d['BTC'].tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>pair</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>base_volume</th>\n",
       "      <th>quote_volume</th>\n",
       "      <th>rolling_base_volume</th>\n",
       "      <th>rolling_quote_volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-11-12 09:00:00</th>\n",
       "      <td>16841.35</td>\n",
       "      <td>16905.22</td>\n",
       "      <td>16800.00</td>\n",
       "      <td>16863.98</td>\n",
       "      <td>1.961440e+08</td>\n",
       "      <td>1.960534e+08</td>\n",
       "      <td>8.580557e+09</td>\n",
       "      <td>8.573127e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-12 10:00:00</th>\n",
       "      <td>16864.46</td>\n",
       "      <td>16977.45</td>\n",
       "      <td>16807.13</td>\n",
       "      <td>16843.88</td>\n",
       "      <td>2.522414e+08</td>\n",
       "      <td>2.527530e+08</td>\n",
       "      <td>8.533088e+09</td>\n",
       "      <td>8.526359e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-12 11:00:00</th>\n",
       "      <td>16842.66</td>\n",
       "      <td>16887.51</td>\n",
       "      <td>16790.30</td>\n",
       "      <td>16866.92</td>\n",
       "      <td>1.583291e+08</td>\n",
       "      <td>1.581320e+08</td>\n",
       "      <td>8.380402e+09</td>\n",
       "      <td>8.373272e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-12 12:00:00</th>\n",
       "      <td>16866.46</td>\n",
       "      <td>16918.29</td>\n",
       "      <td>16809.83</td>\n",
       "      <td>16862.99</td>\n",
       "      <td>1.680811e+08</td>\n",
       "      <td>1.681323e+08</td>\n",
       "      <td>8.265257e+09</td>\n",
       "      <td>8.259148e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-12 13:00:00</th>\n",
       "      <td>16863.46</td>\n",
       "      <td>16869.00</td>\n",
       "      <td>16757.00</td>\n",
       "      <td>16840.79</td>\n",
       "      <td>1.690897e+08</td>\n",
       "      <td>1.689236e+08</td>\n",
       "      <td>7.994280e+09</td>\n",
       "      <td>7.985305e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-12 14:00:00</th>\n",
       "      <td>16839.75</td>\n",
       "      <td>16964.90</td>\n",
       "      <td>16799.28</td>\n",
       "      <td>16900.01</td>\n",
       "      <td>2.279972e+08</td>\n",
       "      <td>2.277357e+08</td>\n",
       "      <td>6.714130e+09</td>\n",
       "      <td>6.712341e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-12 15:00:00</th>\n",
       "      <td>16901.33</td>\n",
       "      <td>16996.35</td>\n",
       "      <td>16873.84</td>\n",
       "      <td>16935.74</td>\n",
       "      <td>2.037338e+08</td>\n",
       "      <td>2.038166e+08</td>\n",
       "      <td>6.220490e+09</td>\n",
       "      <td>6.217950e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-12 16:00:00</th>\n",
       "      <td>16935.74</td>\n",
       "      <td>16964.37</td>\n",
       "      <td>16870.01</td>\n",
       "      <td>16888.68</td>\n",
       "      <td>1.503602e+08</td>\n",
       "      <td>1.505260e+08</td>\n",
       "      <td>5.875942e+09</td>\n",
       "      <td>5.875519e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-12 17:00:00</th>\n",
       "      <td>16889.57</td>\n",
       "      <td>16910.83</td>\n",
       "      <td>16857.47</td>\n",
       "      <td>16891.69</td>\n",
       "      <td>1.320677e+08</td>\n",
       "      <td>1.320214e+08</td>\n",
       "      <td>5.646655e+09</td>\n",
       "      <td>5.647117e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-12 18:00:00</th>\n",
       "      <td>16891.69</td>\n",
       "      <td>16899.99</td>\n",
       "      <td>16830.00</td>\n",
       "      <td>16871.49</td>\n",
       "      <td>1.297863e+08</td>\n",
       "      <td>1.296834e+08</td>\n",
       "      <td>5.445767e+09</td>\n",
       "      <td>5.444339e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-12 19:00:00</th>\n",
       "      <td>16871.49</td>\n",
       "      <td>16902.03</td>\n",
       "      <td>16846.82</td>\n",
       "      <td>16891.32</td>\n",
       "      <td>9.202840e+07</td>\n",
       "      <td>9.194744e+07</td>\n",
       "      <td>5.245862e+09</td>\n",
       "      <td>5.245345e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-12 20:00:00</th>\n",
       "      <td>16892.41</td>\n",
       "      <td>16897.68</td>\n",
       "      <td>16791.71</td>\n",
       "      <td>16820.32</td>\n",
       "      <td>1.059635e+08</td>\n",
       "      <td>1.061303e+08</td>\n",
       "      <td>5.023398e+09</td>\n",
       "      <td>5.021984e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-12 21:00:00</th>\n",
       "      <td>16820.98</td>\n",
       "      <td>16862.50</td>\n",
       "      <td>16767.73</td>\n",
       "      <td>16819.64</td>\n",
       "      <td>1.203129e+08</td>\n",
       "      <td>1.202891e+08</td>\n",
       "      <td>4.859703e+09</td>\n",
       "      <td>4.858681e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-12 22:00:00</th>\n",
       "      <td>16818.73</td>\n",
       "      <td>16858.04</td>\n",
       "      <td>16791.00</td>\n",
       "      <td>16835.63</td>\n",
       "      <td>7.478680e+07</td>\n",
       "      <td>7.475147e+07</td>\n",
       "      <td>4.719146e+09</td>\n",
       "      <td>4.718567e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-12 23:00:00</th>\n",
       "      <td>16835.63</td>\n",
       "      <td>16840.15</td>\n",
       "      <td>16760.00</td>\n",
       "      <td>16812.08</td>\n",
       "      <td>1.323862e+08</td>\n",
       "      <td>1.323209e+08</td>\n",
       "      <td>4.549520e+09</td>\n",
       "      <td>4.550717e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-13 00:00:00</th>\n",
       "      <td>16813.16</td>\n",
       "      <td>16886.00</td>\n",
       "      <td>16774.07</td>\n",
       "      <td>16842.60</td>\n",
       "      <td>1.474327e+08</td>\n",
       "      <td>1.473539e+08</td>\n",
       "      <td>4.398234e+09</td>\n",
       "      <td>4.398288e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-13 01:00:00</th>\n",
       "      <td>16841.84</td>\n",
       "      <td>16905.90</td>\n",
       "      <td>16840.10</td>\n",
       "      <td>16879.34</td>\n",
       "      <td>1.062349e+08</td>\n",
       "      <td>1.061605e+08</td>\n",
       "      <td>4.309831e+09</td>\n",
       "      <td>4.310010e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-13 02:00:00</th>\n",
       "      <td>16878.63</td>\n",
       "      <td>16905.19</td>\n",
       "      <td>16856.99</td>\n",
       "      <td>16895.56</td>\n",
       "      <td>1.114841e+08</td>\n",
       "      <td>1.114915e+08</td>\n",
       "      <td>4.247623e+09</td>\n",
       "      <td>4.247368e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-13 03:00:00</th>\n",
       "      <td>16894.79</td>\n",
       "      <td>16954.28</td>\n",
       "      <td>16865.08</td>\n",
       "      <td>16914.60</td>\n",
       "      <td>1.721966e+08</td>\n",
       "      <td>1.721805e+08</td>\n",
       "      <td>4.189845e+09</td>\n",
       "      <td>4.190160e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-13 04:00:00</th>\n",
       "      <td>16915.02</td>\n",
       "      <td>16926.15</td>\n",
       "      <td>16857.40</td>\n",
       "      <td>16868.06</td>\n",
       "      <td>1.117417e+08</td>\n",
       "      <td>1.118678e+08</td>\n",
       "      <td>4.016833e+09</td>\n",
       "      <td>4.016470e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "pair                     open      high       low     close   base_volume  \\\n",
       "date                                                                        \n",
       "2022-11-12 09:00:00  16841.35  16905.22  16800.00  16863.98  1.961440e+08   \n",
       "2022-11-12 10:00:00  16864.46  16977.45  16807.13  16843.88  2.522414e+08   \n",
       "2022-11-12 11:00:00  16842.66  16887.51  16790.30  16866.92  1.583291e+08   \n",
       "2022-11-12 12:00:00  16866.46  16918.29  16809.83  16862.99  1.680811e+08   \n",
       "2022-11-12 13:00:00  16863.46  16869.00  16757.00  16840.79  1.690897e+08   \n",
       "2022-11-12 14:00:00  16839.75  16964.90  16799.28  16900.01  2.279972e+08   \n",
       "2022-11-12 15:00:00  16901.33  16996.35  16873.84  16935.74  2.037338e+08   \n",
       "2022-11-12 16:00:00  16935.74  16964.37  16870.01  16888.68  1.503602e+08   \n",
       "2022-11-12 17:00:00  16889.57  16910.83  16857.47  16891.69  1.320677e+08   \n",
       "2022-11-12 18:00:00  16891.69  16899.99  16830.00  16871.49  1.297863e+08   \n",
       "2022-11-12 19:00:00  16871.49  16902.03  16846.82  16891.32  9.202840e+07   \n",
       "2022-11-12 20:00:00  16892.41  16897.68  16791.71  16820.32  1.059635e+08   \n",
       "2022-11-12 21:00:00  16820.98  16862.50  16767.73  16819.64  1.203129e+08   \n",
       "2022-11-12 22:00:00  16818.73  16858.04  16791.00  16835.63  7.478680e+07   \n",
       "2022-11-12 23:00:00  16835.63  16840.15  16760.00  16812.08  1.323862e+08   \n",
       "2022-11-13 00:00:00  16813.16  16886.00  16774.07  16842.60  1.474327e+08   \n",
       "2022-11-13 01:00:00  16841.84  16905.90  16840.10  16879.34  1.062349e+08   \n",
       "2022-11-13 02:00:00  16878.63  16905.19  16856.99  16895.56  1.114841e+08   \n",
       "2022-11-13 03:00:00  16894.79  16954.28  16865.08  16914.60  1.721966e+08   \n",
       "2022-11-13 04:00:00  16915.02  16926.15  16857.40  16868.06  1.117417e+08   \n",
       "\n",
       "pair                 quote_volume  rolling_base_volume  rolling_quote_volume  \n",
       "date                                                                          \n",
       "2022-11-12 09:00:00  1.960534e+08         8.580557e+09          8.573127e+09  \n",
       "2022-11-12 10:00:00  2.527530e+08         8.533088e+09          8.526359e+09  \n",
       "2022-11-12 11:00:00  1.581320e+08         8.380402e+09          8.373272e+09  \n",
       "2022-11-12 12:00:00  1.681323e+08         8.265257e+09          8.259148e+09  \n",
       "2022-11-12 13:00:00  1.689236e+08         7.994280e+09          7.985305e+09  \n",
       "2022-11-12 14:00:00  2.277357e+08         6.714130e+09          6.712341e+09  \n",
       "2022-11-12 15:00:00  2.038166e+08         6.220490e+09          6.217950e+09  \n",
       "2022-11-12 16:00:00  1.505260e+08         5.875942e+09          5.875519e+09  \n",
       "2022-11-12 17:00:00  1.320214e+08         5.646655e+09          5.647117e+09  \n",
       "2022-11-12 18:00:00  1.296834e+08         5.445767e+09          5.444339e+09  \n",
       "2022-11-12 19:00:00  9.194744e+07         5.245862e+09          5.245345e+09  \n",
       "2022-11-12 20:00:00  1.061303e+08         5.023398e+09          5.021984e+09  \n",
       "2022-11-12 21:00:00  1.202891e+08         4.859703e+09          4.858681e+09  \n",
       "2022-11-12 22:00:00  7.475147e+07         4.719146e+09          4.718567e+09  \n",
       "2022-11-12 23:00:00  1.323209e+08         4.549520e+09          4.550717e+09  \n",
       "2022-11-13 00:00:00  1.473539e+08         4.398234e+09          4.398288e+09  \n",
       "2022-11-13 01:00:00  1.061605e+08         4.309831e+09          4.310010e+09  \n",
       "2022-11-13 02:00:00  1.114915e+08         4.247623e+09          4.247368e+09  \n",
       "2022-11-13 03:00:00  1.721805e+08         4.189845e+09          4.190160e+09  \n",
       "2022-11-13 04:00:00  1.118678e+08         4.016833e+09          4.016470e+09  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#crypto_output_log_1h = crypto_logger_output_1h.log_name\n",
    "crypto_output_log_1h = 'crypto_logs/crypto_output_log_1h.txt'\n",
    "df_1h = pd.read_csv(crypto_output_log_1h, header=[0, 1], index_col=0)\n",
    "df_1h.index = pd.DatetimeIndex(df_1h.index)\n",
    "df_1h = df_1h.sort_index(axis='index')\n",
    "df_1h['BTC'].tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#crypto_output_log_1min = crypto_logger_output_1min.log_name\n",
    "crypto_output_log_1min = 'crypto_logs/crypto_output_log_1min.txt'\n",
    "df_1min = pd.read_csv(crypto_output_log_1min, header=[0, 1], index_col=0)\n",
    "df_1min.index = pd.DatetimeIndex(df_1min.index)\n",
    "df_1min = df_1min.sort_index(axis='index')\n",
    "df_1min['BTC'].tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = crypto_logger_output_1min.dataset\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['BTCUSDT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['ZILBUSD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_ta as ta\n",
    "\n",
    "def filter_in_market(function, dataset):\n",
    "    def f(x):\n",
    "        x = x.loc[:,~x.columns.duplicated()]\n",
    "        return function(x)\n",
    "    tickers_list = dataset.columns.get_level_values(0).unique().tolist()\n",
    "    return pd.Series([ticker for ticker in tickers_list if f(dataset[ticker])], dtype='str')\n",
    "\n",
    "def get_relative_volume_levels_smoothed_trigger(data, average1=26, average2=14):\n",
    "    volume = data['volume']\n",
    "    volume_average = ta.sma(close=volume, length=average1)\n",
    "    relative_volume = volume / volume_average\n",
    "    smoothed_relative_volume = ta.sma(close=relative_volume, length=average2)\n",
    "    return (smoothed_relative_volume > threshold).iat[-1]\n",
    "\n",
    "def get_relative_volume_levels_at_time_smoothed_thresholded(data):\n",
    "    try:\n",
    "        volume = data['volume']\n",
    "        #volume = volume.groupby(pd.Grouper(freq='D')).cumsum()\n",
    "        cum_volume = volume.groupby(pd.Grouper(freq='24h')).cumsum()\n",
    "        #volume = volume.groupby(pd.Grouper(freq='60m')).cumsum()\n",
    "        cum_rvol = (cum_volume / cum_volume.shift(1)).fillna(method='pad')\n",
    "        rvol = (volume / volume.shift(1)).fillna(method='pad')\n",
    "        bar_up = (data['close'] > data['open'])\n",
    "        bar_up |= (data['close'] == data['open']) & (data['close'].diff() > 0)\n",
    "        bar_up = bar_up.astype(int)\n",
    "        bar_up = bar_up * 2 - 1\n",
    "        #rvol *= bar_up\n",
    "        cum_rvol_dir = cum_rvol * bar_up\n",
    "        rvol_dir = rvol * bar_up\n",
    "        rvol_indicator = ta.hma(rvol, length=14, talib=True)\n",
    "        rvol_dir_indicator = ta.hma(rvol_dir, length=14, talib=True)\n",
    "        cum_rvol_indicator = ta.hma(cum_rvol, length=14, talib=True)\n",
    "        cum_rvol_dir_indicator = ta.hma(cum_rvol_dir, length=14, talib=True)\n",
    "        rvol_indicator = rvol_indicator.rename('relative_volume_levels_smoothed')\n",
    "        rvol_dir_indicator = rvol_dir_indicator.rename('relative_volume_levels_dir_smoothed')\n",
    "        cum_rvol_indicator = cum_rvol_indicator.rename('cum_relative_volume_levels_smoothed')\n",
    "        cum_rvol_dir_indicator = cum_rvol_dir_indicator.rename('cum_relative_volume_levels_dir_smoothed')\n",
    "        #threshold = (ta.sma(rvol, length=100, talib=True) + ta.stdev(rvol, length=100, talib=True))\n",
    "        threshold_dir = 0\n",
    "        threshold = 2\n",
    "        rvol_thresholded = (rvol_indicator > threshold).iat[-1]\n",
    "        rvol_dir_thresholded = (rvol_dir_indicator > threshold_dir).iat[-1]\n",
    "        cum_rvol_thresholded = (cum_rvol_indicator > threshold).iat[-1]\n",
    "        cum_rvol_dir_thresholded = (cum_rvol_dir_indicator > threshold_dir).iat[-1]\n",
    "        trigger = (rvol_thresholded | rvol_dir_thresholded | cum_rvol_thresholded | cum_rvol_dir_thresholded)\n",
    "    except Exception as e:\n",
    "        print('rvol exception:', e)\n",
    "        trigger = False\n",
    "    return trigger\n",
    "\n",
    "def get_positive_trend_strength_trigger(data):\n",
    "    ADX = data.ta.adx(talib=True)\n",
    "    return (ADX['ADX_14'] < 0.20).iloc[-3] & (ADX['ADX_14'] > 0.20).iat[-2]\n",
    "\n",
    "def get_not_negative_trend_strength_trigger(data):\n",
    "    ADX = data.ta.adx(length=14, lensig=8, talib=True)\n",
    "    return ((ADX['DMP_14'] > ADX['DMN_14']) & (ADX['ADX_14'] > 0.30)).iat[-1]\n",
    "\n",
    "def get_not_negative_rebound_trigger(data):\n",
    "    CCI = data.ta.cci(length=22, talib=True)\n",
    "    MFI = data.ta.mfi(length=11, talib=True)\n",
    "    return ((CCI > 0) | (MFI > 20)).iat[-1]\n",
    "\n",
    "def get_positive_choppiness_trigger(data):\n",
    "    CHOP = data.ta.chop(talib=True)\n",
    "    return CHOP.iat[-1] < 38.2\n",
    "\n",
    "def get_positive_phase_trigger(data):\n",
    "    MACD = data.ta.macd(talib=True)\n",
    "    histogram = MACD['MACDs_12_26_9'] - MACD['MACD_12_26_9']\n",
    "    return ((histogram > histogram.shift(1)) | \\\n",
    "            (MACD['MACD_12_26_9'] > MACD['MACDs_12_26_9'])).iat[-1]\n",
    "\n",
    "def get_positive_phase_trigger(data):\n",
    "    MACD = data.ta.macd(talib=True)\n",
    "    histogram = MACD['MACDs_12_26_9'] - MACD['MACD_12_26_9']\n",
    "    return ((histogram.iloc[-2] > histogram.iat[-2]) or \\\n",
    "            (MACD['MACD_12_26_9'].iat[-1] > MACD['MACDs_12_26_9'].iat[-1]))\n",
    "\n",
    "def get_not_square_wave_triggers(data, multiplier_schedule):\n",
    "    triggers = True\n",
    "    for multiplier in multiplier_schedule:\n",
    "        period_1 = -4 * multiplier\n",
    "        uniques_1 = 2 * multiplier\n",
    "        square_wave_trigger_1 = (data.iloc[period_1:]['close'].unique().size < uniques_1)\n",
    "        if square_wave_trigger_1:\n",
    "            triggers = False\n",
    "            break\n",
    "        else:\n",
    "            period_2 = -15 * multiplier\n",
    "            uniques_2 = 6 * multiplier\n",
    "            square_wave_trigger_2 = (data.iloc[period_2:]['close'].unique().size < uniques_2)\n",
    "            if square_wave_trigger_2:\n",
    "                triggers = False\n",
    "                break\n",
    "    return triggers\n",
    "\n",
    "def get_minute_not_square_wave_triggers(data):\n",
    "    return get_not_square_wave_triggers(data, multiplier_schedule=[1, 2, 3, 5, 10, 15, 20, 45])\n",
    "\n",
    "def get_hourly_not_square_wave_triggers(data):\n",
    "    return get_not_square_wave_triggers(data, multiplier_schedule=[1])\n",
    "\n",
    "def get_daily_not_square_wave_triggers(data):\n",
    "    return get_not_square_wave_triggers(data, multiplier_schedule=[1])\n",
    "\n",
    "def get_daily_volume_minimum_trigger(data):\n",
    "    return (data['volume'] > 1000000).iat[-1]\n",
    "\n",
    "def get_daily_volume_change_trigger(data):\n",
    "    return ((data['volume'].pct_change(1) * 100) > 300).iat[-1]\n",
    "\n",
    "def get_minute_daily_volume_minimum_trigger(data):\n",
    "    return (data['rolling_base_volume'] > 1000000).iat[-1]\n",
    "\n",
    "def get_minute_daily_volume_change_trigger(data):\n",
    "    return ((data['rolling_base_volume'].pct_change(1440) * 100) > 300).iat[-1]\n",
    "\n",
    "def get_rising_volume_trigger(data):\n",
    "    return (data['rolling_base_volume'].diff(1) > 0).iat[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_1d.copy()\n",
    "df.columns = df.columns.swaplevel(0, 1)\n",
    "df = df.rename(columns={'base_volume': 'volume'})\n",
    "df.columns = df.columns.swaplevel(0, 1)\n",
    "filtered_1 = set(filter_in_market(get_daily_not_square_wave_triggers, df).tolist())\n",
    "filtered_2 = set(filter_in_market(get_daily_volume_minimum_trigger, df).tolist())\n",
    "filtered_3 = set(filter_in_market(get_relative_volume_levels_smoothed_trigger, df).tolist())\n",
    "filtered_1d = pd.Series(list(filtered_1 & filtered_2 & filtered_3))\n",
    "filtered_1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        XRP\n",
       "1        PSG\n",
       "2        MOB\n",
       "3       AUTO\n",
       "4        HNT\n",
       "       ...  \n",
       "296    BTCST\n",
       "297    TFUEL\n",
       "298      MDT\n",
       "299      BAR\n",
       "300      XMR\n",
       "Length: 301, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_1h.copy()\n",
    "df.columns = df.columns.swaplevel(0, 1)\n",
    "df = df.rename(columns={'base_volume': 'volume'})\n",
    "df.columns = df.columns.swaplevel(0, 1)\n",
    "filtered_1 = set(filter_in_market(get_hourly_not_square_wave_triggers, df).tolist())\n",
    "filtered_2 = set(filter_in_market(get_relative_volume_levels_at_time_smoothed_thresholded, df).tolist())\n",
    "filtered_1h = pd.Series(list(filtered_1 & filtered_2))\n",
    "filtered_1h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cryptocurrency.indicators import filter_in_market, screen_one\n",
    "df = df_1min.copy()\n",
    "df.columns = df.columns.swaplevel(0, 1)\n",
    "df = df.rename(columns={'base_volume': 'volume'})\n",
    "df.columns = df.columns.swaplevel(0, 1)\n",
    "filtered = filter_in_market(screen_one, df).tolist()\n",
    "filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_1min.copy()\n",
    "df.columns = df.columns.swaplevel(0, 1)\n",
    "df = df.rename(columns={'base_volume': 'volume'})\n",
    "df.columns = df.columns.swaplevel(0, 1)\n",
    "filtered_1 = set(filter_in_market(get_minute_not_square_wave_triggers, df).tolist())\n",
    "filtered_2 = set(filter_in_market(get_minute_daily_volume_minimum_trigger, df).tolist())\n",
    "filtered_3 = set(filter_in_market(get_minute_daily_volume_change_trigger, df).tolist())\n",
    "filtered_4 = set(filter_in_market(get_rising_volume_trigger, df).tolist())\n",
    "filtered_1min = pd.Series(list(filtered_1 & filtered_2 & filtered_3 & filtered_4))\n",
    "filtered_1min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(set(filtered_1h.tolist()) & set(filtered_1d.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(set(filtered_1min.tolist()) & set(filtered_1h.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(set(filtered_1min.tolist()) & set(filtered_1d.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(set(filtered_1min.tolist()) & set(filtered_1h.tolist()) & set(filtered_1d.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "crypto_output_log_15s = 'crypto_logs/crypto_output_log_15s.txt'\n",
    "df_15s = pd.read_csv(crypto_output_log_15s, header=[0, 1], index_col=0)\n",
    "df_15s.index = pd.DatetimeIndex(df_15s.index)\n",
    "df_15s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "crypto_exchange_info = 'crypto_logs/crypto_exchange_info.txt'\n",
    "exchange_info = pd.read_csv(crypto_exchange_info, header=0, index_col=0)\n",
    "exchange_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cryptocurrency.authentication import Cryptocurrency_authenticator\n",
    "from cryptocurrency.exchange import Cryptocurrency_exchange\n",
    "from cryptocurrency.conversion_table import get_conversion_table\n",
    "\n",
    "authenticator = Cryptocurrency_authenticator(use_keys=False, testnet=False)\n",
    "client = authenticator.spot_client\n",
    "exchange = Cryptocurrency_exchange(client=client, directory='crypto_logs')\n",
    "exchange_info = exchange.info\n",
    "\n",
    "#conversion_table = get_conversion_table(client=client, exchange_info=exchange_info)\n",
    "#conversion_table.sort_values(by='rolling_traded_volume', ascending=False).reset_index(drop=True).head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cryptocurrency.conversion import get_timezone_offset_in_seconds\n",
    "from cryptocurrency.conversion_table import get_conversion_table\n",
    "\n",
    "offset_s = get_timezone_offset_in_seconds()\n",
    "conversion_table = get_conversion_table(client=client, exchange_info=exchange_info, \n",
    "                                        offset_s=offset_s, as_pair=False)\n",
    "conversion_table.sort_values(by='rolling_base_volume', ascending=False).reset_index(drop=True).head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversion_table['quote_asset'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_connected_assets(asset, exchange_info, priority='accuracy'):\n",
    "    def reorder(connected_assets, priority):\n",
    "        prioritized = [asset for asset in priority if asset in connected_assets]\n",
    "        order = {asset: i for i, asset in enumerate(prioritized)}\n",
    "        connected_assets_items = [asset for asset in connected_assets if asset in order]\n",
    "        connected_assets_items.sort(key=order.get)\n",
    "        connected_assets_iter = iter(connected_assets_items)\n",
    "        return [next(connected_assets_iter) if asset in order \n",
    "                else asset for asset in connected_assets]\n",
    "    priorities = {}\n",
    "    priorities['accuracy'] = ['USDT', 'BTC', 'BUSD', 'ETH', 'BNB', 'AUD']\n",
    "    priorities['fees'] = ['BUSD', 'BTC', 'BNB', 'ETH', 'USDT', 'AUD']\n",
    "    priorities['wallet'] = ['BTC', 'ETH', 'BUSD', 'BNB', 'USDT', 'AUD']\n",
    "    priority = priorities[priority]\n",
    "    connected_base_assets = exchange_info['base_asset'] == asset\n",
    "    connected_base_assets = exchange_info[connected_base_assets]\n",
    "    connected_base_assets = connected_base_assets['quote_asset'].tolist()\n",
    "    connected_quote_assets = exchange_info['quote_asset'] == asset\n",
    "    connected_quote_assets = exchange_info[connected_quote_assets]\n",
    "    connected_quote_assets = connected_quote_assets['base_asset'].tolist()\n",
    "    connected_assets = sorted(list(set(connected_base_assets + connected_quote_assets)))\n",
    "    prioritized = reorder(connected_assets, priority)\n",
    "    return prioritized\n",
    "\n",
    "asset = 'AXS'\n",
    "connected_assets = get_connected_assets(asset, exchange_info, priority='fees')\n",
    "print(connected_assets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol = 'NEBL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "crypto_output_log_1d = 'crypto_logs/crypto_output_log_1d.txt'\n",
    "df_1d = pd.read_csv(crypto_output_log_1d, header=[0, 1], index_col=0)\n",
    "df_1d.index = pd.DatetimeIndex(df_1d.index)\n",
    "df_1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "crypto_output_log_15s = 'crypto_logs/crypto_output_log_15s.txt'\n",
    "df_15s = pd.read_csv(crypto_output_log_15s, header=[0, 1], index_col=0)\n",
    "df_15s.index = pd.DatetimeIndex(df_15s.index)\n",
    "df_15s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_15s[symbol]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "crypto_output_log_1min = 'crypto_logs/crypto_output_log_1min.txt'\n",
    "df_1min = pd.read_csv(crypto_output_log_1min, header=[0, 1], index_col=0)\n",
    "df_1min.index = pd.DatetimeIndex(df_1min.index)\n",
    "df_1min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1min[symbol].tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "crypto_output_log_1h = 'crypto_logs/crypto_output_log_1h.txt'\n",
    "df_1h = pd.read_csv(crypto_output_log_1h, header=[0, 1], index_col=0)\n",
    "df_1h.index = pd.DatetimeIndex(df_1h.index)\n",
    "df_1h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1h[symbol].tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_1h.copy()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tz_local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "df = df_1h.copy()\n",
    "is_dst = time.localtime().tm_isdst\n",
    "timezone = time.tzname[is_dst]\n",
    "offset_ns = time.altzone if is_dst else time.timezone\n",
    "offset = (offset_ns / 60 / 60 * -1)\n",
    "df.index = df.index + pd.Timedelta(-is_dst, unit='h')\n",
    "df.index = df.index.tz_localize(tz=time.tzname[0])\n",
    "df.index = pd.DatetimeIndex(df.index, ambiguous='infer')\n",
    "df.index = df.index.tz_convert('UTC')\n",
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index[-1].dst()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "df.index.to_pydatetime()[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_1min.copy()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cryptocurrency.authentication import Cryptocurrency_authenticator\n",
    "from cryptocurrency.exchange import Cryptocurrency_exchange\n",
    "from cryptocurrency.conversion_table import get_conversion_table\n",
    "import pandas as pd\n",
    "\n",
    "authenticator = Cryptocurrency_authenticator(use_keys=False, testnet=False)\n",
    "client = authenticator.spot_client\n",
    "exchange = Cryptocurrency_exchange(client=client, directory='crypto_logs')\n",
    "exchange_info = exchange.info\n",
    "\n",
    "crypto_output_log_1min = 'crypto_logs/crypto_output_log_1min.txt'\n",
    "df_1min = pd.read_csv(crypto_output_log_1min, header=[0, 1], index_col=0)\n",
    "df_1min.index = pd.DatetimeIndex(df_1min.index)\n",
    "\n",
    "conversion_table = df_1min.copy()\n",
    "conversion_table.columns = conversion_table.columns.swaplevel(0, 1)\n",
    "conversion_table = conversion_table.drop(columns=['rolling_base_volume', \n",
    "                                                  'rolling_quote_volume'])\n",
    "conversion_table.columns = conversion_table.columns.swaplevel(0, 1)\n",
    "conversion_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cryptocurrency.conversion import convert_ohlcvs_from_pairs_to_assets\n",
    "\n",
    "new_conversion_table = convert_ohlcvs_from_pairs_to_assets(conversion_table, \n",
    "                                                           exchange_info)\n",
    "new_conversion_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_conversion_table['ETH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyO4csgmdyxBlfVzNgUhkI0X",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "crypto_bot",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
