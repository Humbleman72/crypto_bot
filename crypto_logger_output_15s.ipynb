{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jKtLwsCCqsmH"
   },
   "source": [
    "Cryptocurrency trading bot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# File:        cryptocurrency/crypto_logger_base.py\n",
    "# By:          Samuel Duclos\n",
    "# For          Myself\n",
    "# Description: Simple Binance logger base class.\n",
    "\n",
    "# Library imports.\n",
    "from cryptocurrency.resample import resample\n",
    "from binance.client import Client\n",
    "from abc import abstractmethod, ABC\n",
    "from time import sleep, time\n",
    "from os.path import exists, join\n",
    "from os import mkdir\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "class Crypto_logger_base(ABC):\n",
    "    def __init__(self, interval='15s', delay=4.7, buffer_size=3000, directory='crypto_logs', \n",
    "                 log_name='crypto_log', raw=False):\n",
    "        \"\"\"\n",
    "        :param interval: OHLCV interval to log. Default is 15 seconds.\n",
    "        :param delay: delay between Binance API requests. Minimum calculated was 4.7 seconds.\n",
    "        :param buffer_size: buffer size to avoid crashing on memory accesses.\n",
    "        :param directory: the directory where to output the logs.\n",
    "        :param log_name: name of the log file.\n",
    "        :param raw: whether the log dumps raw (instantaneous) or OHLCV data.\n",
    "        \"\"\"\n",
    "        self.interval = interval\n",
    "        self.delay = delay\n",
    "        self.buffer_size = buffer_size\n",
    "        self.directory = directory\n",
    "        self.raw = raw\n",
    "\n",
    "        self.log_name = join(self.directory, log_name + '.txt')\n",
    "        self.log_screened_name = join(self.directory, log_name + '_screened.txt')\n",
    "\n",
    "        if not exists(self.directory):\n",
    "            mkdir(self.directory)\n",
    "\n",
    "    #self.get_from_file(log_name=self.log_name, from_raw=False)\n",
    "    #self.get_from_file(log_name=self.input_log_name, from_raw=self.load_from_ohlcv)\n",
    "    def get_from_file(self, log_name, from_raw=False):\n",
    "        if from_raw:\n",
    "            dataset = pd.read_csv(log_name, header=0, index_col=0)\n",
    "        else:\n",
    "            dataset = pd.read_csv(log_name, header=[0, 1], index_col=0)\n",
    "        dataset.index = pd.DatetimeIndex(dataset.index)\n",
    "        return dataset.sort_index(axis='index')\n",
    "\n",
    "    @abstractmethod\n",
    "    def get(self, **kwargs):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    @abstractmethod\n",
    "    def screen(self, **kwargs):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def put(self, dataset):\n",
    "        dataset = dataset.copy().reset_index()\n",
    "        if self.raw:\n",
    "            dataset = dataset.drop_duplicates(subset=['symbol', 'count'], \n",
    "                                              keep='first', ignore_index=True)\n",
    "        else:\n",
    "            dataset = dataset.drop_duplicates(keep='last', ignore_index=True)\n",
    "\n",
    "        if 'date' in dataset.columns:\n",
    "            min_index_int = dataset[dataset['date'] == self.min_index].index[0]\n",
    "            dataset = dataset.set_index('date')\n",
    "        if not self.raw:\n",
    "            dataset = resample(dataset, self.interval)\n",
    "        if 'date' in dataset.columns:\n",
    "            dataset = dataset.iloc[min_index_int:]\n",
    "\n",
    "        dataset = dataset.tail(self.buffer_size)\n",
    "        dataset.to_csv(self.log_name)\n",
    "        self.min_index = dataset.index[0]\n",
    "        return dataset\n",
    "\n",
    "    def start(self, append=False, roll=0):\n",
    "        \"\"\"Main logger loop.\"\"\"\n",
    "        print('Starting crypto logger.')\n",
    "\n",
    "        if exists(self.log_name) and 'output' in self.log_name:\n",
    "            self.dataset = self.get_from_file(log_name=self.log_name, from_raw=False)\n",
    "            self.dataset = self.dataset.tail(self.buffer_size)\n",
    "        else:\n",
    "            self.dataset = self.get()\n",
    "\n",
    "        self.min_index = self.dataset.index[-1]\n",
    "        self.dataset = self.put(self.dataset)\n",
    "\n",
    "        while True:\n",
    "            try:\n",
    "                dataset = pd.concat([self.dataset, self.get()], axis='index', join='outer')\n",
    "            except (KeyboardInterrupt, SystemExit):\n",
    "                print('User terminated crypto logger process.')\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "            try:\n",
    "                self.dataset = self.put(dataset)\n",
    "            except (KeyboardInterrupt, SystemExit):\n",
    "                print('Saving latest complete dataset...')\n",
    "                self.dataset = self.put(dataset)\n",
    "                print('User terminated crypto logger process.')\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "            try:\n",
    "                if exists(self.log_screened_name):\n",
    "                    dataset_screened_old = \\\n",
    "                        pd.read_csv(self.log_screened_name, index_col=0, header=0)\n",
    "                else:\n",
    "                    dataset_screened_old = None\n",
    "                dataset_screened = self.screen(self.dataset)\n",
    "                if dataset_screened is not None:\n",
    "                    if roll != 0:\n",
    "                        if append and exists(self.log_screened_name):\n",
    "                            dataset_screened = \\\n",
    "                                pd.concat([dataset_screened_old, dataset_screened], axis='index')\n",
    "                            dataset_screened = \\\n",
    "                                dataset_screened.drop_duplicates(subset=['symbol'], keep='last')\n",
    "                        dataset_screened = dataset_screened.tail(roll)\n",
    "                        dataset_screened.to_csv(self.log_screened_name)\n",
    "                    elif append:\n",
    "                        dataset_screened.to_csv(self.log_screened_name, mode='a')\n",
    "                    else:\n",
    "                        dataset_screened.to_csv(self.log_screened_name)\n",
    "            except (KeyboardInterrupt, SystemExit):\n",
    "                print('User terminated crypto logger process.')\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "            sleep(self.delay)\n",
    "        print('Crypto logger process done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# File:        cryptocurrency/crypto_logger_output.py\n",
    "# By:          Samuel Duclos\n",
    "# For          Myself\n",
    "# Description: Simple Binance logger output for arbitrary intervals.\n",
    "\n",
    "# Library imports.\n",
    "#from cryptocurrency.crypto_logger_base import Crypto_logger_base\n",
    "from cryptocurrency.indicators import filter_in_market, screen_one\n",
    "from os.path import exists, join\n",
    "\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "class Crypto_logger_output(Crypto_logger_base):\n",
    "    def __init__(self, delay=12, interval_input='15s', interval='15s', buffer_size=60, \n",
    "                 input_log_name='input'):\n",
    "        \"\"\"\n",
    "        :param delay: delay between logger/screener service interruptions.\n",
    "        :param interval_input: OHLCV interval from input log. Default is 15 seconds.\n",
    "        :param interval: OHLCV interval to log. Default is 15 seconds.\n",
    "        :param buffer_size: buffer size to avoid crashing on memory accesses.\n",
    "        :param input_log_name: the directory where to take the logs from.\n",
    "        \"\"\"\n",
    "        self.data_before = pd.DataFrame()\n",
    "        input_log_name = 'crypto_' + input_log_name + '_log_'\n",
    "        self.load_from_ohlcv = interval_input != interval\n",
    "        super().__init__(interval=interval, delay=delay, buffer_size=buffer_size, \n",
    "                         directory='crypto_logs', log_name='crypto_output_log_' + interval, \n",
    "                         raw=False)\n",
    "\n",
    "        self.input_log_name = \\\n",
    "            join(self.directory, input_log_name + interval_input + '.txt')\n",
    "        self.input_log_screened_name = \\\n",
    "            join(self.directory, input_log_name + interval_input + '_screened.txt')\n",
    "\n",
    "    def screen(self, dataset):\n",
    "        input_filtered = None\n",
    "        if exists(self.input_log_screened_name):\n",
    "            input_filtered = pd.read_csv(self.input_log_screened_name, header=0, index_col=0)\n",
    "            input_filter = set(input_filtered['symbol'].tolist())\n",
    "            old_columns = set(dataset.columns.get_level_values(0).tolist())\n",
    "            new_columns = list(input_filter & old_columns)\n",
    "            dataset = dataset[new_columns]\n",
    "            assets = filter_in_market(screen_one, dataset)\n",
    "            input_filtered = input_filtered[input_filtered['symbol'].isin(assets)]\n",
    "        return input_filtered\n",
    "\n",
    "    def resample_from_raw(self, df):\n",
    "        df = df[['symbol', 'close', 'rolling_base_volume', 'rolling_quote_volume']]\n",
    "        df['base_volume'] = df['rolling_base_volume'].copy()\n",
    "        df['quote_volume'] = df['rolling_quote_volume'].copy()\n",
    "        df = df.pivot_table(index=['date'], columns=['symbol'], \n",
    "                            values=['close', 'rolling_base_volume', \n",
    "                                    'rolling_quote_volume', \n",
    "                                    'base_volume', 'quote_volume'], \n",
    "                            aggfunc={'close': ['first', 'max', 'min', 'last'], \n",
    "                                     'base_volume': 'max', 'quote_volume': 'max', \n",
    "                                     'rolling_base_volume': 'max', \n",
    "                                     'rolling_quote_volume': 'max'})\n",
    "        df.columns = pd.MultiIndex.from_tuples([('_'.join(col[:2]), col[2]) \n",
    "                                                for col in df.columns.values], \n",
    "                                               names=('pair', 'symbol'))\n",
    "        df = df.rename(columns={'close_first': 'open', 'close_max': 'high', \n",
    "                                'close_min': 'low', 'close_last': 'close', \n",
    "                                'base_volume_max': 'base_volume', \n",
    "                                'quote_volume_max': 'quote_volume', \n",
    "                                'rolling_base_volume_max': 'rolling_base_volume', \n",
    "                                'rolling_quote_volume_max': 'rolling_quote_volume'}, \n",
    "                       level=0)\n",
    "        df['base_volume'] = df['base_volume'].fillna(0)\n",
    "        df['quote_volume'] = df['quote_volume'].fillna(0)\n",
    "        df['rolling_base_volume'] = df['rolling_base_volume'].fillna(method='pad').fillna(0)\n",
    "        df['rolling_quote_volume'] = df['rolling_quote_volume'].fillna(method='pad').fillna(0)\n",
    "        df = df.sort_index().iloc[1:]\n",
    "        df.columns = df.columns.swaplevel(0, 1)\n",
    "        return df\n",
    "\n",
    "    def get(self):\n",
    "        dataset = self.get_from_file(log_name=self.input_log_name, \n",
    "                                     from_raw=not self.load_from_ohlcv)\n",
    "        if not self.load_from_ohlcv:\n",
    "            dataset = self.resample_from_raw(dataset)\n",
    "        return dataset.tail(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# File:        crypto_logger_output_1min.py\n",
    "# By:          Samuel Duclos\n",
    "# For          Myself\n",
    "# Description: Simple Binance logger output for the 1 minute interval.\n",
    "\n",
    "# Library imports.\n",
    "#from cryptocurrency.crypto_logger_output import Crypto_logger_output\n",
    "\n",
    "crypto_logger_output_1min = Crypto_logger_output(delay=33, \n",
    "                                                 interval_input='15s', \n",
    "                                                 interval='15s', \n",
    "                                                 buffer_size=60, \n",
    "                                                 input_log_name='output')\n",
    "crypto_logger_output_1min.start(append=False, roll=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "input_log_name = 'crypto_logs/crypto_input_log_15s.txt'\n",
    "df = pd.read_csv(input_log_name, header=0, index_col=0)\n",
    "df.index = pd.DatetimeIndex(df.index)\n",
    "df = df.sort_index(axis='index')\n",
    "#df = crypto_logger_output_1min.resample_from_raw(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#crypto_output_log_1d = crypto_logger_output_1d.log_name\n",
    "crypto_output_log_1d = 'crypto_logs/crypto_output_log_1d.txt'\n",
    "df_1d = pd.read_csv(crypto_output_log_1d, header=[0, 1], index_col=0)\n",
    "df_1d.index = pd.DatetimeIndex(df_1d.index)\n",
    "df_1d = df_1d.sort_index(axis='index')\n",
    "df_1d['BTC'].tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#crypto_output_log_1h = crypto_logger_output_1h.log_name\n",
    "crypto_output_log_1h = 'crypto_logs/crypto_output_log_1h.txt'\n",
    "df_1h = pd.read_csv(crypto_output_log_1h, header=[0, 1], index_col=0)\n",
    "df_1h.index = pd.DatetimeIndex(df_1h.index)\n",
    "df_1h = df_1h.sort_index(axis='index')\n",
    "df_1h['BTC'].tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#crypto_output_log_1min = crypto_logger_output_1min.log_name\n",
    "crypto_output_log_1min = 'crypto_logs/crypto_output_log_1min.txt'\n",
    "df_1min = pd.read_csv(crypto_output_log_1min, header=[0, 1], index_col=0)\n",
    "df_1min.index = pd.DatetimeIndex(df_1min.index)\n",
    "df_1min = df_1min.sort_index(axis='index')\n",
    "df_1min['BTC'].tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = crypto_logger_output_1min.dataset\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['BTCUSDT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['ZILBUSD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_ta as ta\n",
    "\n",
    "def filter_in_market(function, dataset):\n",
    "    def f(x):\n",
    "        x = x.loc[:,~x.columns.duplicated()]\n",
    "        return function(x)\n",
    "    tickers_list = dataset.columns.get_level_values(0).unique().tolist()\n",
    "    return pd.Series([ticker for ticker in tickers_list if f(dataset[ticker])], dtype='str')\n",
    "\n",
    "def get_relative_volume_levels_smoothed_trigger(data, average1=26, average2=14):\n",
    "    volume = data['volume']\n",
    "    volume_average = ta.sma(close=volume, length=average1)\n",
    "    relative_volume = volume / volume_average\n",
    "    smoothed_relative_volume = ta.sma(close=relative_volume, length=average2)\n",
    "    return (smoothed_relative_volume > threshold).iat[-1]\n",
    "\n",
    "def get_relative_volume_levels_at_time_smoothed_thresholded(data):\n",
    "    try:\n",
    "        volume = data['volume']\n",
    "        #volume = volume.groupby(pd.Grouper(freq='D')).cumsum()\n",
    "        cum_volume = volume.groupby(pd.Grouper(freq='24h')).cumsum()\n",
    "        #volume = volume.groupby(pd.Grouper(freq='60m')).cumsum()\n",
    "        cum_rvol = (cum_volume / cum_volume.shift(1)).fillna(method='pad')\n",
    "        rvol = (volume / volume.shift(1)).fillna(method='pad')\n",
    "        bar_up = (data['close'] > data['open'])\n",
    "        bar_up |= (data['close'] == data['open']) & (data['close'].diff() > 0)\n",
    "        bar_up = bar_up.astype(int)\n",
    "        bar_up = bar_up * 2 - 1\n",
    "        #rvol *= bar_up\n",
    "        cum_rvol_dir = cum_rvol * bar_up\n",
    "        rvol_dir = rvol * bar_up\n",
    "        rvol_indicator = ta.hma(rvol, length=14, talib=True)\n",
    "        rvol_dir_indicator = ta.hma(rvol_dir, length=14, talib=True)\n",
    "        cum_rvol_indicator = ta.hma(cum_rvol, length=14, talib=True)\n",
    "        cum_rvol_dir_indicator = ta.hma(cum_rvol_dir, length=14, talib=True)\n",
    "        rvol_indicator = rvol_indicator.rename('relative_volume_levels_smoothed')\n",
    "        rvol_dir_indicator = rvol_dir_indicator.rename('relative_volume_levels_dir_smoothed')\n",
    "        cum_rvol_indicator = cum_rvol_indicator.rename('cum_relative_volume_levels_smoothed')\n",
    "        cum_rvol_dir_indicator = cum_rvol_dir_indicator.rename('cum_relative_volume_levels_dir_smoothed')\n",
    "        #threshold = (ta.sma(rvol, length=100, talib=True) + ta.stdev(rvol, length=100, talib=True))\n",
    "        threshold_dir = 0\n",
    "        threshold = 2\n",
    "        rvol_thresholded = (rvol_indicator > threshold).iat[-1]\n",
    "        rvol_dir_thresholded = (rvol_dir_indicator > threshold_dir).iat[-1]\n",
    "        cum_rvol_thresholded = (cum_rvol_indicator > threshold).iat[-1]\n",
    "        cum_rvol_dir_thresholded = (cum_rvol_dir_indicator > threshold_dir).iat[-1]\n",
    "        trigger = (rvol_thresholded | rvol_dir_thresholded | cum_rvol_thresholded | cum_rvol_dir_thresholded)\n",
    "    except Exception as e:\n",
    "        print('rvol exception:', e)\n",
    "        trigger = False\n",
    "    return trigger\n",
    "\n",
    "def get_positive_trend_strength_trigger(data):\n",
    "    ADX = data.ta.adx(talib=True)\n",
    "    return (ADX['ADX_14'] < 0.20).iloc[-3] & (ADX['ADX_14'] > 0.20).iat[-2]\n",
    "\n",
    "def get_not_negative_trend_strength_trigger(data):\n",
    "    ADX = data.ta.adx(length=14, lensig=8, talib=True)\n",
    "    return ((ADX['DMP_14'] > ADX['DMN_14']) & (ADX['ADX_14'] > 0.30)).iat[-1]\n",
    "\n",
    "def get_not_negative_rebound_trigger(data):\n",
    "    CCI = data.ta.cci(length=22, talib=True)\n",
    "    MFI = data.ta.mfi(length=11, talib=True)\n",
    "    return ((CCI > 0) | (MFI > 20)).iat[-1]\n",
    "\n",
    "def get_positive_choppiness_trigger(data):\n",
    "    CHOP = data.ta.chop(talib=True)\n",
    "    return CHOP.iat[-1] < 38.2\n",
    "\n",
    "def get_positive_phase_trigger(data):\n",
    "    MACD = data.ta.macd(talib=True)\n",
    "    histogram = MACD['MACDs_12_26_9'] - MACD['MACD_12_26_9']\n",
    "    return ((histogram > histogram.shift(1)) | \\\n",
    "            (MACD['MACD_12_26_9'] > MACD['MACDs_12_26_9'])).iat[-1]\n",
    "\n",
    "def get_positive_phase_trigger(data):\n",
    "    MACD = data.ta.macd(talib=True)\n",
    "    histogram = MACD['MACDs_12_26_9'] - MACD['MACD_12_26_9']\n",
    "    return ((histogram.iloc[-2] > histogram.iat[-2]) or \\\n",
    "            (MACD['MACD_12_26_9'].iat[-1] > MACD['MACDs_12_26_9'].iat[-1]))\n",
    "\n",
    "def get_not_square_wave_triggers(data, multiplier_schedule):\n",
    "    triggers = True\n",
    "    for multiplier in multiplier_schedule:\n",
    "        period_1 = -4 * multiplier\n",
    "        uniques_1 = 2 * multiplier\n",
    "        square_wave_trigger_1 = (data.iloc[period_1:]['close'].unique().size < uniques_1)\n",
    "        if square_wave_trigger_1:\n",
    "            triggers = False\n",
    "            break\n",
    "        else:\n",
    "            period_2 = -15 * multiplier\n",
    "            uniques_2 = 6 * multiplier\n",
    "            square_wave_trigger_2 = (data.iloc[period_2:]['close'].unique().size < uniques_2)\n",
    "            if square_wave_trigger_2:\n",
    "                triggers = False\n",
    "                break\n",
    "    return triggers\n",
    "\n",
    "def get_minute_not_square_wave_triggers(data):\n",
    "    return get_not_square_wave_triggers(data, multiplier_schedule=[1, 2, 3, 5, 10, 15, 20, 45])\n",
    "\n",
    "def get_hourly_not_square_wave_triggers(data):\n",
    "    return get_not_square_wave_triggers(data, multiplier_schedule=[1, 2, 3, 4, 6, 8, 12])\n",
    "\n",
    "def get_daily_not_square_wave_triggers(data):\n",
    "    return get_not_square_wave_triggers(data, multiplier_schedule=[1])\n",
    "\n",
    "def get_daily_volume_minimum_trigger(data):\n",
    "    return (data['volume'] > 1000000).iat[-1]\n",
    "\n",
    "def get_daily_volume_change_trigger(data):\n",
    "    return ((data['volume'].pct_change(1) * 100) > 300).iat[-1]\n",
    "\n",
    "def get_minute_daily_volume_minimum_trigger(data):\n",
    "    return (data['rolling_base_volume'] > 1000000).iat[-1]\n",
    "\n",
    "def get_minute_daily_volume_change_trigger(data):\n",
    "    return ((data['rolling_base_volume'].pct_change(1440) * 100) > 300).iat[-1]\n",
    "\n",
    "def get_rising_volume_trigger(data):\n",
    "    return (data['rolling_base_volume'].diff(1) > 0).iat[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_1d.copy()\n",
    "df.columns = df.columns.swaplevel(0, 1)\n",
    "df = df.rename(columns={'base_volume': 'volume'})\n",
    "df.columns = df.columns.swaplevel(0, 1)\n",
    "filtered_1 = set(filter_in_market(get_daily_not_square_wave_triggers, df).tolist())\n",
    "filtered_2 = set(filter_in_market(get_daily_volume_minimum_trigger, df).tolist())\n",
    "filtered_3 = set(filter_in_market(get_relative_volume_levels_smoothed_trigger, df).tolist())\n",
    "filtered_1d = pd.Series(list(filtered_1 & filtered_2 & filtered_3))\n",
    "filtered_1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_1h.copy()\n",
    "df.columns = df.columns.swaplevel(0, 1)\n",
    "df = df.rename(columns={'base_volume': 'volume'})\n",
    "df.columns = df.columns.swaplevel(0, 1)\n",
    "filtered_1 = set(filter_in_market(get_hourly_not_square_wave_triggers, df).tolist())\n",
    "filtered_2 = set(filter_in_market(get_relative_volume_levels_at_time_smoothed_thresholded, df).tolist())\n",
    "filtered_1h = pd.Series(list(filtered_1 & filtered_2))\n",
    "filtered_1h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cryptocurrency.indicators import filter_in_market, screen_one\n",
    "df = df_1min.copy()\n",
    "df.columns = df.columns.swaplevel(0, 1)\n",
    "df = df.rename(columns={'base_volume': 'volume'})\n",
    "df.columns = df.columns.swaplevel(0, 1)\n",
    "filtered = filter_in_market(screen_one, df).tolist()\n",
    "filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_1min.copy()\n",
    "df.columns = df.columns.swaplevel(0, 1)\n",
    "df = df.rename(columns={'base_volume': 'volume'})\n",
    "df.columns = df.columns.swaplevel(0, 1)\n",
    "filtered_1 = set(filter_in_market(get_minute_not_square_wave_triggers, df).tolist())\n",
    "filtered_2 = set(filter_in_market(get_minute_daily_volume_minimum_trigger, df).tolist())\n",
    "filtered_3 = set(filter_in_market(get_minute_daily_volume_change_trigger, df).tolist())\n",
    "filtered_4 = set(filter_in_market(get_rising_volume_trigger, df).tolist())\n",
    "filtered_1min = pd.Series(list(filtered_1 & filtered_2 & filtered_3 & filtered_4))\n",
    "filtered_1min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(set(filtered_1h.tolist()) & set(filtered_1d.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(set(filtered_1min.tolist()) & set(filtered_1h.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(set(filtered_1min.tolist()) & set(filtered_1d.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(set(filtered_1min.tolist()) & set(filtered_1h.tolist()) & set(filtered_1d.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "crypto_output_log_15s = 'crypto_logs/crypto_output_log_15s.txt'\n",
    "df_15s = pd.read_csv(crypto_output_log_15s, header=[0, 1], index_col=0)\n",
    "df_15s.index = pd.DatetimeIndex(df_15s.index)\n",
    "df_15s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "crypto_exchange_info = 'crypto_logs/crypto_exchange_info.txt'\n",
    "exchange_info = pd.read_csv(crypto_exchange_info, header=0, index_col=0)\n",
    "exchange_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cryptocurrency.authentication import Cryptocurrency_authenticator\n",
    "from cryptocurrency.exchange import Cryptocurrency_exchange\n",
    "from cryptocurrency.conversion_table import get_conversion_table\n",
    "\n",
    "authenticator = Cryptocurrency_authenticator(use_keys=False, testnet=False)\n",
    "client = authenticator.spot_client\n",
    "exchange = Cryptocurrency_exchange(client=client, directory='crypto_logs')\n",
    "exchange_info = exchange.info\n",
    "\n",
    "#conversion_table = get_conversion_table(client=client, exchange_info=exchange_info)\n",
    "#conversion_table.sort_values(by='rolling_traded_volume', ascending=False).reset_index(drop=True).head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cryptocurrency.conversion import get_timezone_offset_in_seconds\n",
    "from cryptocurrency.conversion_table import get_conversion_table\n",
    "\n",
    "offset_s = get_timezone_offset_in_seconds()\n",
    "conversion_table = get_conversion_table(client=client, exchange_info=exchange_info, \n",
    "                                        offset_s=offset_s, as_pair=False)\n",
    "conversion_table.sort_values(by='rolling_base_volume', ascending=False).reset_index(drop=True).head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversion_table['quote_asset'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_connected_assets(asset, exchange_info):\n",
    "    connected_base_assets = exchange_info['base_asset'] == asset\n",
    "    connected_base_assets = exchange_info[connected_base_assets]\n",
    "    connected_base_assets = connected_base_assets['quote_asset'].tolist()\n",
    "    connected_quote_assets = exchange_info['quote_asset'] == asset\n",
    "    connected_quote_assets = exchange_info[connected_quote_assets]\n",
    "    connected_quote_assets = connected_quote_assets['base_asset'].tolist()\n",
    "    connected_assets = sorted(list(set(connected_base_assets + connected_quote_assets)))\n",
    "    if 'BNB' in connected_assets and 'BTC' in connected_assets:\n",
    "        BNB, BTC = connected_assets.index('BNB'), connected_assets.index('BTC')\n",
    "        connected_assets[BNB], connected_assets[BTC] = \\\n",
    "            connected_assets[BTC], connected_assets[BNB]\n",
    "    if 'BNB' in connected_assets and 'BUSD' in connected_assets:\n",
    "        BNB, BUSD = connected_assets.index('BNB'), connected_assets.index('BUSD')\n",
    "        connected_assets[BNB], connected_assets[BUSD] = \\\n",
    "            connected_assets[BUSD], connected_assets[BNB]\n",
    "    if 'BNB' in connected_assets and 'ETH' in connected_assets:\n",
    "        BNB, ETH = connected_assets.index('BNB'), connected_assets.index('ETH')\n",
    "        connected_assets[BNB], connected_assets[ETH] = \\\n",
    "            connected_assets[ETH], connected_assets[BNB]\n",
    "    if 'ETH' in connected_assets and 'BUSD' in connected_assets:\n",
    "        ETH, BUSD = connected_assets.index('ETH'), connected_assets.index('BUSD')\n",
    "        connected_assets[ETH], connected_assets[BUSD] = \\\n",
    "            connected_assets[BUSD], connected_assets[ETH]\n",
    "    return connected_assets\n",
    "\n",
    "asset = 'BNB'\n",
    "connected_assets = get_connected_assets(asset, exchange_info)\n",
    "print(connected_assets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol = 'NEBL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "crypto_output_log_1d = 'crypto_logs/crypto_output_log_1d.txt'\n",
    "df_1d = pd.read_csv(crypto_output_log_1d, header=[0, 1], index_col=0)\n",
    "df_1d.index = pd.DatetimeIndex(df_1d.index)\n",
    "df_1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "crypto_output_log_15s = 'crypto_logs/crypto_output_log_15s.txt'\n",
    "df_15s = pd.read_csv(crypto_output_log_15s, header=[0, 1], index_col=0)\n",
    "df_15s.index = pd.DatetimeIndex(df_15s.index)\n",
    "df_15s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_15s[symbol]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "crypto_output_log_1min = 'crypto_logs/crypto_output_log_1min.txt'\n",
    "df_1min = pd.read_csv(crypto_output_log_1min, header=[0, 1], index_col=0)\n",
    "df_1min.index = pd.DatetimeIndex(df_1min.index)\n",
    "df_1min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1min[symbol].tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "crypto_output_log_1h = 'crypto_logs/crypto_output_log_1h.txt'\n",
    "df_1h = pd.read_csv(crypto_output_log_1h, header=[0, 1], index_col=0)\n",
    "df_1h.index = pd.DatetimeIndex(df_1h.index)\n",
    "df_1h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1h[symbol].tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_1h.copy()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tz_local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "df = df_1h.copy()\n",
    "is_dst = time.localtime().tm_isdst\n",
    "timezone = time.tzname[is_dst]\n",
    "offset_ns = time.altzone if is_dst else time.timezone\n",
    "offset = (offset_ns / 60 / 60 * -1)\n",
    "df.index = df.index + pd.Timedelta(-is_dst, unit='h')\n",
    "df.index = df.index.tz_localize(tz=time.tzname[0])\n",
    "df.index = pd.DatetimeIndex(df.index, ambiguous='infer')\n",
    "df.index = df.index.tz_convert('UTC')\n",
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index[-1].dst()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "df.index.to_pydatetime()[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_1min.copy()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cryptocurrency.authentication import Cryptocurrency_authenticator\n",
    "from cryptocurrency.exchange import Cryptocurrency_exchange\n",
    "from cryptocurrency.conversion_table import get_conversion_table\n",
    "import pandas as pd\n",
    "\n",
    "authenticator = Cryptocurrency_authenticator(use_keys=False, testnet=False)\n",
    "client = authenticator.spot_client\n",
    "exchange = Cryptocurrency_exchange(client=client, directory='crypto_logs')\n",
    "exchange_info = exchange.info\n",
    "\n",
    "crypto_output_log_1min = 'crypto_logs/crypto_output_log_1min.txt'\n",
    "df_1min = pd.read_csv(crypto_output_log_1min, header=[0, 1], index_col=0)\n",
    "df_1min.index = pd.DatetimeIndex(df_1min.index)\n",
    "\n",
    "conversion_table = df_1min.copy()\n",
    "conversion_table.columns = conversion_table.columns.swaplevel(0, 1)\n",
    "conversion_table = conversion_table.drop(columns=['rolling_base_volume', \n",
    "                                                  'rolling_quote_volume'])\n",
    "conversion_table.columns = conversion_table.columns.swaplevel(0, 1)\n",
    "conversion_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cryptocurrency.conversion import convert_ohlcvs_from_pairs_to_assets\n",
    "\n",
    "new_conversion_table = convert_ohlcvs_from_pairs_to_assets(conversion_table, \n",
    "                                                           exchange_info)\n",
    "new_conversion_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_conversion_table['ETH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyO4csgmdyxBlfVzNgUhkI0X",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "crypto_bot",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
