{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jKtLwsCCqsmH"
   },
   "source": [
    "Cryptocurrency trading bot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# File:        cryptocurrency/crypto_logger_base.py\n",
    "# By:          Samuel Duclos\n",
    "# For          Myself\n",
    "# Description: Simple Binance logger base class.\n",
    "\n",
    "# Library imports.\n",
    "from binance.client import Client\n",
    "from abc import abstractmethod, ABC\n",
    "from time import sleep, time\n",
    "from os.path import exists, join\n",
    "from os import mkdir\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "class Crypto_logger_base(ABC):\n",
    "    def __init__(self, interval='1min', delay=4.7, buffer_size=20000, directory='crypto_logs', \n",
    "                 log_name='crypto_log', second_screener=False, raw=False, precise=True):\n",
    "        \"\"\"\n",
    "        :param interval: OHLCV interval to log. Default is 1 minute.\n",
    "        :param delay: delay between Binance API requests. Minimum calculated was 5 seconds.\n",
    "        :param buffer_size: buffer size to avoid crashing on low memory.\n",
    "        :param directory: the directory where to output the logs.\n",
    "        :param log_name: name of the log file.\n",
    "        :param raw: whether the log dumps raw (instantaneous) or OHLCV data.\n",
    "        \"\"\"\n",
    "        self.interval = interval\n",
    "        self.delay = delay\n",
    "        self.buffer_size = buffer_size\n",
    "        self.directory = directory\n",
    "        self.raw = raw\n",
    "        self.precise = precise\n",
    "\n",
    "        self.log_name = join(self.directory, log_name + '.txt')\n",
    "        self.log_screened_name = join(self.directory, log_name + '_screened.txt')\n",
    "        self.log_screened_2_name = join(self.directory, log_name + '_screened_2.txt')\n",
    "        self.second_screener = second_screener and 'output' in self.log_screened_2_name\n",
    "\n",
    "        if not exists(self.directory):\n",
    "            mkdir(self.directory)\n",
    "\n",
    "    @abstractmethod\n",
    "    def screen(self, **kwargs):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    #@abstractmethod\n",
    "    #def screen_2(self, **kwargs):\n",
    "    #    raise NotImplementedError()\n",
    "\n",
    "    @abstractmethod\n",
    "    def get(self, **kwargs):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def recalculate_volumes(self, df, df_old):\n",
    "        df.columns = df.columns.swaplevel(0, 1)\n",
    "        df_old.columns = df_old.columns.swaplevel(0, 1)\n",
    "        df = pd.concat([df, df_old[['base_volume', 'quote_volume']]], \n",
    "                       join='outer', axis='columns')\n",
    "        print(df_old.columns)\n",
    "        df.columns = df.columns.swaplevel(0, 1)\n",
    "        df = df.stack(level=1).reset_index(level=1)\n",
    "        df[df['pair'] == 'base_volume'].iloc[:,1:] = \\\n",
    "            df[df['pair'] == 'rolling_base_volume'].iloc[:,1:].diff(1) + \\\n",
    "            df[df['pair'] == 'base_volume'].iloc[:,1:].shift(1440)\n",
    "        df[df['pair'] == 'quote_volume'].iloc[:,1:] = \\\n",
    "            df[df['pair'] == 'rolling_quote_volume'].iloc[:,1:].diff(1) + \\\n",
    "            df[df['pair'] == 'quote_volume'].iloc[:,1:].shift(1440)\n",
    "        df = df.reset_index().pivot_table(index=['date'], columns=['pair'], \n",
    "                                          values=df.columns[1:])\n",
    "        return df[['open', 'high', 'low', 'close', \n",
    "                   'base_volume', 'quote_volume', \n",
    "                   'rolling_base_volume', \n",
    "                   'rolling_quote_volume']]\n",
    "\n",
    "    def resample(self, df):\n",
    "        df.index = pd.DatetimeIndex(df.index).round(self.interval)\n",
    "        df = df.stack(level=0).reset_index(level=1)\n",
    "        frequency = pd.tseries.frequencies.to_offset((df.index[1:] - df.index[:-1]).min())\n",
    "        frequency_1min = pd.tseries.frequencies.to_offset('1min')\n",
    "        if frequency > frequency_1min:\n",
    "            df = df.pivot_table(index=['date'], columns=['symbol'], \n",
    "                                values=['open', 'high', 'low', 'close', \n",
    "                                        'base_volume', 'quote_volume', \n",
    "                                        'rolling_base_volume', \n",
    "                                        'rolling_quote_volume'], \n",
    "                                aggfunc={'open': 'first', 'high': 'max', \n",
    "                                         'low': 'min', 'close': 'last', \n",
    "                                         'base_volume': 'sum', \n",
    "                                         'quote_volume': 'sum', \n",
    "                                         'rolling_base_volume': 'sum', \n",
    "                                         'rolling_quote_volume': 'sum'})\n",
    "        else:\n",
    "            df = df.pivot_table(index=['date'], columns=['symbol'], \n",
    "                                values=['open', 'high', 'low', 'close', \n",
    "                                        'rolling_base_volume', \n",
    "                                        'rolling_quote_volume'], \n",
    "                                aggfunc={'open': 'first', 'high': 'max', \n",
    "                                         'low': 'min', 'close': 'last', \n",
    "                                         'rolling_base_volume': 'max', \n",
    "                                         'rolling_quote_volume': 'max'})\n",
    "\n",
    "        if frequency == frequency_1min:\n",
    "            df = recalculate_volumes(df, self.dataset)\n",
    "\n",
    "        df.columns = df.columns.swaplevel(0, 1)\n",
    "        return df.sort_index()\n",
    "\n",
    "    def put(self, dataset):\n",
    "        dataset = dataset.copy().reset_index()\n",
    "        if self.raw:\n",
    "            dataset = dataset.drop_duplicates(subset=['symbol', 'count'], \n",
    "                                              keep='first', ignore_index=True)\n",
    "        else:\n",
    "            dataset = dataset.drop_duplicates(keep='last', ignore_index=True)\n",
    "\n",
    "        if 'date' in dataset.columns:\n",
    "            min_index_int = dataset[dataset['date'] == self.min_index].index[0]\n",
    "            dataset = dataset.set_index('date')\n",
    "        if not self.raw:\n",
    "            dataset = self.resample(dataset)\n",
    "        if 'date' in dataset.columns:\n",
    "            dataset = dataset.iloc[min_index_int:]\n",
    "\n",
    "        dataset = dataset.tail(self.buffer_size)\n",
    "        dataset.to_csv(self.log_name)\n",
    "        self.min_index = dataset.index[0]\n",
    "        return dataset\n",
    "\n",
    "    def start(self, append=False, roll=0):\n",
    "        \"\"\"Main logger loop.\"\"\"\n",
    "        print('Starting crypto logger.')\n",
    "\n",
    "        if exists(self.log_name) and 'output' in self.log_name:\n",
    "            self.dataset = pd.read_csv(self.log_name, header=[0, 1], index_col=0)\n",
    "            self.dataset = self.dataset.sort_index()\n",
    "        else:\n",
    "            self.dataset = self.get()\n",
    "\n",
    "        self.min_index = self.dataset.index[-1]\n",
    "        self.dataset = self.put(self.dataset)\n",
    "        if self.precise:\n",
    "            t1 = time()\n",
    "\n",
    "        while True:\n",
    "            try:\n",
    "                dataset = pd.concat([self.dataset, self.get()], axis='index', join='outer')\n",
    "            except (KeyboardInterrupt, SystemExit):\n",
    "                print('User terminated crypto logger process.')\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "            try:\n",
    "                self.dataset = self.put(dataset)\n",
    "            except (KeyboardInterrupt, SystemExit):\n",
    "                print('Saving latest complete dataset...')\n",
    "                self.dataset = self.put(dataset)\n",
    "                print('User terminated crypto logger process.')\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "            '''\n",
    "            try:\n",
    "                if exists(self.log_screened_name):\n",
    "                    dataset_screened_old = \\\n",
    "                        pd.read_csv(self.log_screened_name, index_col=0, header=0)\n",
    "                else:\n",
    "                    dataset_screened_old = None\n",
    "                if self.second_screener and exists(self.log_screened_2_name):\n",
    "                    dataset_screened_2_old = \\\n",
    "                        pd.read_csv(self.log_screened_2_name, index_col=0, header=0)\n",
    "                else:\n",
    "                    dataset_screened_2_old = None\n",
    "                dataset_screened = self.screen(self.dataset)\n",
    "                if self.second_screener:\n",
    "                    dataset_screened_2 = self.screen_2(dataset_screened)\n",
    "                if roll != 0:\n",
    "                    if append and exists(self.log_screened_name):\n",
    "                        if dataset_screened is not None:\n",
    "                            dataset_screened = \\\n",
    "                                pd.concat([dataset_screened_old, dataset_screened], axis='index')\n",
    "                            dataset_screened = \\\n",
    "                                dataset_screened.drop_duplicates(subset=['symbol'], keep='last')\n",
    "                        if self.second_screener and exists(self.log_screened_2_name) and dataset_screened_2 is not None:\n",
    "                            dataset_screened_2 = \\\n",
    "                                pd.concat([dataset_screened_2_old, dataset_screened_2], axis='index')\n",
    "                            dataset_screened_2 = \\\n",
    "                                dataset_screened_2.drop_duplicates(subset=['symbol'], keep='last')\n",
    "                    if dataset_screened is not None:\n",
    "                        dataset_screened = dataset_screened.tail(roll)\n",
    "                        dataset_screened.to_csv(self.log_screened_name)\n",
    "                    if self.second_screener and exists(self.log_screened_2_name) and dataset_screened_2 is not None:\n",
    "                        dataset_screened_2 = dataset_screened_2.tail(roll)\n",
    "                        dataset_screened_2.to_csv(self.log_screened_2_name)\n",
    "                elif append:\n",
    "                    if dataset_screened is not None:\n",
    "                        dataset_screened.to_csv(self.log_screened_name, mode='a')\n",
    "                    if self.second_screener and dataset_screened_2 is not None:\n",
    "                        dataset_screened_2.to_csv(self.log_screened_2_name, mode='a')\n",
    "                else:\n",
    "                    if dataset_screened is not None:\n",
    "                        dataset_screened.to_csv(self.log_screened_name)\n",
    "                    if self.second_screener and dataset_screened_2 is not None:\n",
    "                        dataset_screened_2.to_csv(self.log_screened_2_name)\n",
    "            '''\n",
    "            try:\n",
    "                if exists(self.log_screened_name):\n",
    "                    dataset_screened_old = \\\n",
    "                        pd.read_csv(self.log_screened_name, index_col=0, header=0)\n",
    "                else:\n",
    "                    dataset_screened_old = None\n",
    "                dataset_screened = self.screen(self.dataset)\n",
    "                if dataset_screened is not None:\n",
    "                    if roll != 0:\n",
    "                        if append and exists(self.log_screened_name):\n",
    "                            dataset_screened = \\\n",
    "                                pd.concat([dataset_screened_old, dataset_screened], axis='index')\n",
    "                            dataset_screened = \\\n",
    "                                dataset_screened.drop_duplicates(subset=['symbol'], keep='last')\n",
    "                        dataset_screened = dataset_screened.tail(roll)\n",
    "                        dataset_screened.to_csv(self.log_screened_name)\n",
    "                    elif append:\n",
    "                        dataset_screened.to_csv(self.log_screened_name, mode='a')\n",
    "                    else:\n",
    "                        dataset_screened.to_csv(self.log_screened_name)\n",
    "            except (KeyboardInterrupt, SystemExit):\n",
    "                print('User terminated crypto logger process.')\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "            if self.precise:\n",
    "                t2 = time()\n",
    "                if t2 - t1 < self.delay:\n",
    "                    sleep(t2 - t1 + self.delay)\n",
    "                t1 = t2\n",
    "            else:\n",
    "                sleep(self.delay)\n",
    "        print('Crypto logger process done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# File:        cryptocurrency/crypto_logger_output.py\n",
    "# By:          Samuel Duclos\n",
    "# For          Myself\n",
    "# Description: Simple Binance logger output for arbitrary intervals.\n",
    "\n",
    "\n",
    "# Library imports.\n",
    "from cryptocurrency.crypto_logger_base import Crypto_logger_base\n",
    "from cryptocurrency.renko import get_renko_trigger\n",
    "from os import mkdir\n",
    "from os.path import exists, join\n",
    "from sys import float_info as sflt\n",
    "from numpy import log\n",
    "from pandas_ta.utils._core import signed_series, recent_minimum_index\n",
    "\n",
    "import datetime\n",
    "import pandas_ta as ta\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "class Crypto_logger_output(Crypto_logger_base):\n",
    "    def __init__(self, delay=6, interval_input='15s', interval='15s', buffer_size=100, \n",
    "                 input_log_name='input', second_screener=False):\n",
    "        \"\"\"\n",
    "        :param delay: delay between Binance API requests. Minimum calculated was 5 seconds.\n",
    "        :param interval_input: OHLCV interval from input log. Default is 15 seconds.\n",
    "        :param interval: OHLCV interval to log. Default is 15 seconds.\n",
    "        :param buffer_size: buffer size to avoid crashing on low memory.\n",
    "        :param directory: the directory where to output the logs.\n",
    "        \"\"\"\n",
    "        self.data_before = pd.DataFrame()\n",
    "        input_log_name = 'crypto_' + input_log_name + '_log_'\n",
    "        self.load_from_ohlcv = interval_input != interval\n",
    "        super().__init__(interval=interval, delay=delay, buffer_size=buffer_size, \n",
    "                         directory='crypto_logs', log_name='crypto_output_log_' + interval, \n",
    "                         second_screener=second_screener, raw=False, precise=True)\n",
    "\n",
    "        #if not self.load_from_ohlcv:\n",
    "        #    self.input_log_screened_up_name = \\\n",
    "        #        join(self.directory, input_log_name + interval_input + '_screened_up.txt')\n",
    "\n",
    "        self.input_log_name = \\\n",
    "            join(self.directory, input_log_name + interval_input + '.txt')\n",
    "        self.input_log_screened_name = \\\n",
    "            join(self.directory, input_log_name + interval_input + '_screened.txt')\n",
    "\n",
    "    def get_screened(self, data_after, price_threshold=5.0, volume_threshold=300.0):\n",
    "        price_movers = pd.DataFrame()\n",
    "        volume_movers = pd.DataFrame()\n",
    "        data_before = self.data_before\n",
    "        if data_before.size != 0:\n",
    "            data_before.columns = data_before.columns.swaplevel(0, 1)\n",
    "            data_after.columns = data_after.columns.swaplevel(0, 1)\n",
    "            price_before = data_before['close'].pct_change(1)\n",
    "            price_after = data_after['close'].pct_change(1)\n",
    "            volume_before = data_before['volume'].shift(1)\n",
    "            volume_after = data_after['volume'].shift(1)\n",
    "            price_percent_change_before = \\\n",
    "                ((data_before['close'].pct_change(1) - price_before) / price_before)\n",
    "            price_percent_change_after = \\\n",
    "                ((data_after['close'].pct_change(1) - price_after) / price_after)\n",
    "            volume_percent_change_before = ((data_before['volume'] - volume_before) / volume_before)\n",
    "            volume_percent_change_after = ((data_after['volume'] - volume_after) / volume_after)\n",
    "            price_movers = \\\n",
    "                ((price_percent_change_after - price_percent_change_before) * 100) > price_threshold\n",
    "            volume_movers = \\\n",
    "                ((volume_percent_change_after - volume_percent_change_before) * 100) > volume_threshold\n",
    "            price_movers = data_after[price_movers].columns.tolist()\n",
    "            volume_movers = data_after[volume_movers].columns.tolist()\n",
    "            data_before.columns = data_before.columns.swaplevel(0, 1)\n",
    "            data_after.columns = data_after.columns.swaplevel(0, 1)\n",
    "        self.data_before = data_after\n",
    "        return price_movers + volume_movers\n",
    "\n",
    "    def screen(self, dataset):\n",
    "        def filter_in_market(function, dataset):\n",
    "            def f(x):\n",
    "                x = x.loc[:,~x.columns.duplicated()]\n",
    "                return function(x)\n",
    "            tickers_list = dataset.columns.get_level_values(0).unique().tolist()\n",
    "            return pd.Series([ticker for ticker in tickers_list if f(dataset[ticker])], dtype='str')\n",
    "\n",
    "        def get_relative_volume_levels_smoothed_thresholded(data):\n",
    "            try:\n",
    "                volume = data['volume']\n",
    "                #volume = volume.groupby(pd.Grouper(freq='D')).cumsum()\n",
    "                volume = volume.groupby(pd.Grouper(freq='24h')).cumsum()\n",
    "                #volume = volume.groupby(pd.Grouper(freq='60m')).cumsum()\n",
    "                rvol = (volume / volume.shift(1))\n",
    "                rvol = rvol.fillna(method='pad')\n",
    "                bar_up = (ticker['close'] > ticker['open'])\n",
    "                bar_up |= (ticker['close'] == ticker['open']) & (ticker['close'].diff() > 0)\n",
    "                bar_up = bar_up.astype(int)\n",
    "                bar_up = bar_up * 2 - 1\n",
    "                rvol *= bar_up\n",
    "                rvol_indicator = ta.hma(rvol, length=14, talib=True)\n",
    "                rvol_indicator = rvol_indicator.rename('relative_volume_levels_smoothed')\n",
    "                #threshold = (ta.sma(rvol, length=100, talib=True) + ta.stdev(rvol, length=100, talib=True))\n",
    "                threshold = 2\n",
    "                rvol_thresholded = (rvol_indicator > threshold).iloc[-1]\n",
    "            except:\n",
    "                rvol_thresholded = False\n",
    "            return rvol_thresholded\n",
    "\n",
    "        def get_not_square_wave_trigger_1(data):\n",
    "            return not (data.iloc[-4:]['close'].unique().size < 2)\n",
    "\n",
    "        def get_not_square_wave_trigger_2(data):\n",
    "            return not (data.iloc[-15:]['close'].unique().size < 6)\n",
    "\n",
    "        def get_not_square_wave_trigger_3(data):\n",
    "            return (data[['open', 'high', 'low', 'close']].nunique(axis='columns') > 2).tail(2).all()\n",
    "\n",
    "        def get_bullish_price_trigger(data):\n",
    "            return (data['close'] > data['high'].shift(1)).iloc[-1]\n",
    "\n",
    "        def get_positive_RSI_trigger(data):\n",
    "            RSI_6 = data.ta.rsi(length=6, talib=True)\n",
    "            RSI_12 = data.ta.rsi(length=12, talib=True)\n",
    "            RSI_24 = data.ta.rsi(length=24, talib=True)\n",
    "            data = ((RSI_6 > RSI_12) | (RSI_6 > RSI_24) | (RSI_12 > RSI_24))\n",
    "            return data.iloc[-1]\n",
    "\n",
    "        def get_positive_momentum_trigger(data):\n",
    "            KDJ = data.ta.kdj(length=5, signal=3, talib=True)\n",
    "            return ((KDJ['J_5_3'] > KDJ['D_5_3']) & (KDJ['J_5_3'] > KDJ['K_5_3'])).iloc[-1]\n",
    "\n",
    "        def get_positive_JMA_trigger(data):\n",
    "            JMA = data.ta.jma(length=7, phase=0, talib=True)\n",
    "            return (data['close'] < JMA).iloc[-1]\n",
    "\n",
    "        def get_ease_of_movement(data):\n",
    "            eom = ((data['high'] - data['low']) / (2 * data['volume'] + 1))\n",
    "            eom *= (data['high'].diff(1) + data['low'].diff(1))\n",
    "            precision = eom.abs().max()\n",
    "            if precision < 1:\n",
    "                eom *= 1 / precision\n",
    "            return eom\n",
    "\n",
    "        def get_ease_of_movement_trigger(data):\n",
    "            data[['open', 'high', 'low', 'close']] += sflt.epsilon\n",
    "            data[['volume']] += 1\n",
    "\n",
    "            log_price = log(data['close'])\n",
    "            price_trough_index = recent_minimum_index(signed_series(log_price, initial=None))\n",
    "            price_slope = ta.slope(close=log_price, length=price_trough_index, as_angle=True, \n",
    "                                   to_degrees=True, talib=True)\n",
    "\n",
    "            EOM = get_ease_of_movement(data)\n",
    "            EOM_trough_index = recent_minimum_index(signed_series(EOM, initial=None))\n",
    "            EOM_slope = ta.slope(close=EOM, length=EOM_trough_index, as_angle=True, \n",
    "                                 to_degrees=True, talib=True)\n",
    "\n",
    "            trigger = (price_slope <= EOM_slope)\n",
    "            #trigger &= (EOM_slope >= 0.25)\n",
    "            trigger &= (EOM_slope > 0.0)\n",
    "\n",
    "            #breakout_trigger = ((EOM.shift(1) < 0.0) & (EOM > 0.0))\n",
    "            #trigger |= breakout_trigger\n",
    "            return trigger.iloc[-1]\n",
    "\n",
    "        '''\n",
    "        def get_positive_PVR_trigger(data):\n",
    "            price = data['close']\n",
    "            volume = data['volume']\n",
    "            volume.iloc[-1] *= volume_multiplier\n",
    "            price_trigger = (price.diff() > 0)\n",
    "            volume_trigger = (volume.diff() > 0)\n",
    "            trigger = (price_trigger & volume_trigger)\n",
    "            return trigger.iloc[-1]\n",
    "        '''\n",
    "\n",
    "        def get_rising_volume_trigger(data):\n",
    "            return (data['rolling_base_volume'].diff(1) > 0).iloc[-1]\n",
    "\n",
    "        def get_RSI_reversal_trigger(data, rsi_length=2, upper_threshold=95, \n",
    "                                     lower_threshold=5, positive=True):\n",
    "            RSI = data.ta.rsi(length=rsi_length, talib=True)\n",
    "            RSI_prev = RSI.shift(1)\n",
    "            thresholds_bear = -((RSI_prev >= upper_threshold) & (RSI < upper_threshold)).astype(int)\n",
    "            thresholds_bull = ((RSI_prev <= lower_threshold) & (RSI > lower_threshold)).astype(int)\n",
    "            thresholds = (thresholds_bear + thresholds_bull)\n",
    "            thresholds = thresholds.replace(to_replace=0, method='pad')\n",
    "            return (thresholds == (1 if positive else -1)).iloc[-1]\n",
    "\n",
    "        def get_heikin_ashi_trigger(data):\n",
    "            def get_positive_trend_strength_trigger(data):\n",
    "                ADX = data.ta.adx(talib=True)\n",
    "                return (ADX['ADX_14'] < 0.20).iloc[-3] and (ADX['ADX_14'] > 0.20).iloc[-2]\n",
    "\n",
    "            def get_not_negative_trend_strength_trigger(data):\n",
    "                ADX = data.ta.adx(length=14, lensig=8, talib=True)\n",
    "                return ((ADX['DMP_14'] > ADX['DMN_14']) and (ADX['ADX_14'] > 0.30)).iloc[-1]\n",
    "\n",
    "            def get_not_negative_rebound_trigger(data):\n",
    "                CCI = data.ta.cci(length=22, talib=True)\n",
    "                MFI = data.ta.mfi(length=11, talib=True)\n",
    "                return ((CCI > 0) or (MFI > 20)).iloc[-1]\n",
    "\n",
    "            def get_positive_choppiness_trigger(data):\n",
    "                CHOP = data.ta.chop(talib=True)\n",
    "                return CHOP.iloc[-1] < 38.2\n",
    "\n",
    "            def get_positive_phase_trigger(data):\n",
    "                MACD = data.ta.macd(talib=True)\n",
    "                histogram = MACD['MACDs_12_26_9'] - MACD['MACD_12_26_9']\n",
    "                return ((histogram.iloc[-1] > histogram.iloc[-2]) or \\\n",
    "                        (MACD['MACD_12_26_9'].iloc[-1] > MACD['MACDs_12_26_9'].iloc[-1]))\n",
    "\n",
    "            def get_positive_RSI_trigger(data):\n",
    "                RSI_5 = data.ta.rsi(length=5, talib=True)\n",
    "                return ((RSI_5 >= 60) & (RSI_5 <= 65)).iloc[-1]\n",
    "\n",
    "            def get_negative_PVR_trigger(data):\n",
    "                price_trigger = (data['close'].iloc[-1] < data['close'].iloc[-2])\n",
    "                volume_trigger = (data['volume'].iloc[-1] > data['volume'].iloc[-2])\n",
    "                return price_trigger and volume_trigger\n",
    "\n",
    "            def get_buy_trigger(data):\n",
    "                return get_not_negative_rebound_trigger(data) and \\\n",
    "                        (get_positive_choppiness_trigger(data) or \\\n",
    "                        get_positive_trend_strength_trigger(data))\n",
    "\n",
    "            def get_sell_trigger(data):\n",
    "                return (((not get_positive_choppiness_trigger(data)) or \\\n",
    "                         get_negative_trend_strength_trigger(data) or \\\n",
    "                         (not get_positive_phase_trigger(data))) or \\\n",
    "                        get_not_negative_rebound_trigger(data))\n",
    "\n",
    "            heikin_ashi = data.ta.ha(talib=True)\n",
    "            heikin_ashi_dataset_1 = heikin_ashi.rename(columns={'HA_open': 'open', \n",
    "                                                                'HA_high': 'high', \n",
    "                                                                'HA_low': 'low', \n",
    "                                                                'HA_close': 'close'})\n",
    "            #heikin_ashi = heikin_ashi_dataset_1.ta.ha(talib=True)\n",
    "            #heikin_ashi_dataset_2 = heikin_ashi.rename(columns={'HA_open': 'open', \n",
    "            #                                                    'HA_high': 'high', \n",
    "            #                                                    'HA_low': 'low', \n",
    "            #                                                    'HA_close': 'close'})\n",
    "            #heikin_ashi = heikin_ashi_dataset_2.ta.ha(talib=True)\n",
    "            #heikin_ashi_dataset_3 = heikin_ashi.rename(columns={'HA_open': 'open', \n",
    "            #                                                    'HA_high': 'high', \n",
    "            #                                                    'HA_low': 'low', \n",
    "            #                                                    'HA_close': 'close'})\n",
    "            #if get_not_negative_rebound_trigger(heikin_ashi_dataset_1):\n",
    "            #    return True\n",
    "            return True \\\n",
    "                if get_positive_phase_trigger(heikin_ashi_dataset_1) \\\n",
    "                else (get_not_negative_rebound_trigger(heikin_ashi_dataset_1) or \\\n",
    "                      get_not_negative_trend_strength_trigger(heikin_ashi_dataset_1))\n",
    "\n",
    "        def screen_one(pair):\n",
    "            frequency = pd.tseries.frequencies.to_offset((pair.index[1:] - pair.index[:-1]).min())\n",
    "            frequency_1min = pd.tseries.frequencies.to_offset('1min')\n",
    "            frequency_30min = pd.tseries.frequencies.to_offset('30min')\n",
    "            frequency_1h = pd.tseries.frequencies.to_offset('1h')\n",
    "            if frequency < frequency_1min:\n",
    "                pair['volume'] = pair['rolling_base_volume'].copy()\n",
    "            else:\n",
    "                pair['volume'] = pair['base_volume'].copy()\n",
    "            if frequency == frequency_30min:\n",
    "                if get_not_square_wave_trigger_1(pair):\n",
    "                    if get_not_square_wave_trigger_2(pair):\n",
    "                        #if get_bullish_price_trigger(pair):\n",
    "                        #if get_heikin_ashi_trigger(pair):\n",
    "                        if get_renko_trigger(pair, compress=False, \n",
    "                                             direction_type='long', \n",
    "                                             trigger_type='simple', \n",
    "                                             method='atr', plot=False):\n",
    "                            return True\n",
    "            elif frequency == frequency_1h:\n",
    "                if get_relative_volume_levels_smoothed_thresholded(pair):\n",
    "                    return True\n",
    "            else:\n",
    "                if get_not_square_wave_trigger_1(pair):\n",
    "                    if get_not_square_wave_trigger_2(pair):\n",
    "                        if frequency < frequency_1min:\n",
    "                            return True \n",
    "                        else:\n",
    "                            if get_rising_volume_trigger(pair):\n",
    "                                if get_heikin_ashi_trigger(pair):\n",
    "                                    return True\n",
    "            return False\n",
    "\n",
    "        #if not self.load_from_ohlcv:\n",
    "        #    if exists(self.input_log_screened_up_name):\n",
    "        #        input_filtered_up = pd.read_csv(self.input_log_screened_up_name, header=0, index_col=None)\n",
    "        if exists(self.input_log_screened_name):\n",
    "            input_filtered = pd.read_csv(self.input_log_screened_name, header=0, index_col=0)\n",
    "            input_filter = set(input_filtered['symbol'].tolist())\n",
    "            #if not self.load_from_ohlcv:\n",
    "            #    input_filter = input_filter & set(input_filtered_up['symbol'].tolist())\n",
    "            old_columns = set(dataset.columns.get_level_values(0).tolist())\n",
    "            new_columns = list(input_filter & old_columns)\n",
    "            dataset = dataset[new_columns]\n",
    "\n",
    "            #assets = self.get_screened(dataset, price_threshold=1.0, volume_threshold=1.0)\n",
    "            #input_filtered_movers = input_filtered[input_filtered['symbol'].isin(assets)]\n",
    "            #input_filtered_movers.to_csv(self.input_log_screened_name, mode='a')\n",
    "            assets = filter_in_market(screen_one, dataset)\n",
    "            return input_filtered[input_filtered['symbol'].isin(assets)]\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def screen_(self, dataset):\n",
    "        return dataset\n",
    "\n",
    "    def resample_from_raw(self, df):\n",
    "        df = df[['symbol', 'lastPrice', 'volume', 'quoteVolume']]\n",
    "        df = df.rename(columns={'lastPrice': 'close', \n",
    "                                'volume': 'rolling_base_volume', \n",
    "                                'quoteVolume': 'rolling_quote_volume'})\n",
    "        df = df.pivot_table(index=['date'], columns=['symbol'], \n",
    "                            values=['close', 'rolling_base_volume', \n",
    "                                    'rolling_quote_volume'], \n",
    "                            aggfunc={'close': ['first', 'max', 'min', 'last'], \n",
    "                                     'rolling_base_volume': 'max', \n",
    "                                     'rolling_quote_volume': 'max'})\n",
    "        df.columns = pd.MultiIndex.from_tuples([('_'.join(col[:2]), col[2]) for col in df.columns.values], \n",
    "                                               names=(None, 'symbol'))\n",
    "        df = df.rename(columns={'close_first': 'open', \n",
    "                                'close_max': 'high', \n",
    "                                'close_min': 'low', \n",
    "                                'close_last': 'close', \n",
    "                                'rolling_base_volume_max': 'rolling_base_volume', \n",
    "                                'rolling_quote_volume_max': 'rolling_quote_volume'}, \n",
    "                       level=0)\n",
    "        df['rolling_base_volume'] = df['rolling_base_volume'].fillna(method='pad')\n",
    "        df['rolling_base_volume'].iloc[0] = 0\n",
    "        df['rolling_quote_volume'] = df['rolling_quote_volume'].fillna(method='pad')\n",
    "        df['rolling_quote_volume'].iloc[0] = 0\n",
    "        df = df.sort_index().iloc[1:]\n",
    "        df.columns = df.columns.swaplevel(0, 1)\n",
    "        return df\n",
    "\n",
    "    def get(self):\n",
    "        if self.load_from_ohlcv:\n",
    "            dataset = pd.read_csv(self.input_log_name, header=[0, 1], index_col=0)\n",
    "        else:\n",
    "            dataset = pd.read_csv(self.input_log_name, header=0, index_col=0)\n",
    "            dataset = self.resample_from_raw(dataset)\n",
    "        return dataset.sort_index().tail(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# File:        crypto_logger_output_1min.py\n",
    "# By:          Samuel Duclos\n",
    "# For          Myself\n",
    "# Description: Simple Binance logger output for the 1 minute interval.\n",
    "\n",
    "# Library imports.\n",
    "#from cryptocurrency.crypto_logger_output import Crypto_logger_output\n",
    "\n",
    "'''\n",
    "crypto_logger_output_1min = Crypto_logger_output(delay=8, interval_input='1min', \n",
    "                                                 interval='1min', buffer_size=100, \n",
    "                                                 input_log_name='input')\n",
    "crypto_logger_output_1min.start(append=False, roll=1000)\n",
    "'''\n",
    "\n",
    "crypto_logger_output_1min = Crypto_logger_output(delay=8, interval_input='30s', \n",
    "                                                 interval='1min', buffer_size=2000, \n",
    "                                                 input_log_name='output')\n",
    "crypto_logger_output_1min.start(append=False, roll=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = crypto_logger_output_1min.dataset\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['BTCUSDT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['ZILBUSD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_in_market(function, dataset):\n",
    "    def f(x):\n",
    "        x = x.loc[:,~x.columns.duplicated()]\n",
    "        return function(x)\n",
    "    tickers_list = dataset.columns.get_level_values(0).unique().tolist()\n",
    "    return pd.Series([ticker for ticker in tickers_list if f(dataset[ticker])], dtype='str')\n",
    "\n",
    "def get_positive_trend_strength_trigger(data):\n",
    "    ADX = data.ta.adx(talib=True)\n",
    "    return (ADX['ADX_14'] < 0.20).iloc[-3] & (ADX['ADX_14'] > 0.20).iloc[-2]\n",
    "\n",
    "def get_not_negative_trend_strength_trigger(data):\n",
    "    ADX = data.ta.adx(length=14, lensig=8, talib=True)\n",
    "    return ((ADX['DMP_14'] > ADX['DMN_14']) & (ADX['ADX_14'] > 0.30)).iloc[-1]\n",
    "\n",
    "def get_not_negative_rebound_trigger(data):\n",
    "    CCI = data.ta.cci(length=22, talib=True)\n",
    "    MFI = data.ta.mfi(length=11, talib=True)\n",
    "    return ((CCI > 0) | (MFI > 20)).iloc[-1]\n",
    "\n",
    "def get_positive_choppiness_trigger(data):\n",
    "    CHOP = data.ta.chop(talib=True)\n",
    "    return CHOP.iloc[-1] < 38.2\n",
    "\n",
    "def get_positive_phase_trigger(data):\n",
    "    MACD = data.ta.macd(talib=True)\n",
    "    histogram = MACD['MACDs_12_26_9'] - MACD['MACD_12_26_9']\n",
    "    return ((histogram > histogram.shift(1)) | \\\n",
    "            (MACD['MACD_12_26_9'] > MACD['MACDs_12_26_9'])).iloc[-1]\n",
    "\n",
    "def get_positive_phase_trigger(data):\n",
    "    MACD = data.ta.macd(talib=True)\n",
    "    histogram = MACD['MACDs_12_26_9'] - MACD['MACD_12_26_9']\n",
    "    return ((histogram.iloc[-2] > histogram.iloc[-2]) or \\\n",
    "            (MACD['MACD_12_26_9'].iloc[-1] > MACD['MACDs_12_26_9'].iloc[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_in_market(get_positive_phase_trigger, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_positive_phase_trigger(df['BTCUSDT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def filter_in_market(function, dataset):\n",
    "    def f(x):\n",
    "        x = x.loc[:,~x.columns.duplicated()]\n",
    "        return function(x)\n",
    "    tickers_list = dataset.columns.get_level_values(0).unique().tolist()\n",
    "    return pd.Series([ticker for ticker in tqdm(tickers_list, unit=' ticker') if f(dataset[ticker])], dtype='str')\n",
    "\n",
    "def get_heikin_ashi_trigger(ticker):\n",
    "    def get_trend_strength_entry_trigger(heikin_ashi_dataset):\n",
    "        ADX = heikin_ashi_dataset.ta.adx(talib=True)\n",
    "        return (ADX['ADX_14'] < 0.20).iloc[-3] and (ADX['ADX_14'] > 0.20).iloc[-2]\n",
    "\n",
    "    def get_not_negative_rebound_trigger(heikin_ashi_dataset):\n",
    "        CCI = heikin_ashi_dataset.ta.cci(talib=True)\n",
    "        return CCI.iloc[-1] < 100\n",
    "\n",
    "    def get_positive_choppiness_trigger(heikin_ashi_dataset):\n",
    "        CHOP = heikin_ashi_dataset.ta.chop(talib=True)\n",
    "        return CHOP.iloc[-1] < 38.2\n",
    "\n",
    "    def get_buy_trigger(heikin_ashi_dataset):\n",
    "        return get_not_negative_rebound_trigger(heikin_ashi_dataset) and \\\n",
    "               (get_positive_choppiness_trigger(heikin_ashi_dataset) or \\\n",
    "                get_trend_strength_entry_trigger(heikin_ashi_dataset))\n",
    "\n",
    "    heikin_ashi = ticker.ta.ha(talib=True)\n",
    "    heikin_ashi_dataset = heikin_ashi.rename(columns={'HA_open': 'open', \n",
    "                                                      'HA_high': 'high', \n",
    "                                                      'HA_low': 'low', \n",
    "                                                      'HA_close': 'close'})\n",
    "    try:\n",
    "        trigger = get_buy_trigger(heikin_ashi_dataset)\n",
    "    except:\n",
    "        trigger = False\n",
    "    return trigger\n",
    "\n",
    "tickers_list = filter_in_market(get_heikin_ashi_trigger, dataset)\n",
    "tickers_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heikin_ashi = dataset['BTCUSDT'].ta.ha(talib=True)\n",
    "heikin_ashi_dataset = heikin_ashi.rename(columns={'HA_open': 'open', \n",
    "                                                  'HA_high': 'high', \n",
    "                                                  'HA_low': 'low', \n",
    "                                                  'HA_close': 'close'})\n",
    "ADX = heikin_ashi_dataset.ta.adx(talib=True)\n",
    "ADX[['DMP_14', 'DMN_14']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol = 'NEBLBUSD'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "crypto_output_log_1d = 'crypto_logs/crypto_output_log_1d.txt'\n",
    "df_1d = pd.read_csv(crypto_output_log_1d, header=[0, 1], index_col=0)\n",
    "df_1d.index = pd.DatetimeIndex(df_1d.index)\n",
    "df_1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "crypto_output_log_30s = 'crypto_logs/crypto_output_log_30s.txt'\n",
    "df_30s = pd.read_csv(crypto_output_log_30s, header=[0, 1], index_col=0)\n",
    "df_30s.index = pd.DatetimeIndex(df_30s.index)\n",
    "df_30s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>symbol</th>\n",
       "      <th>1INCHBTC</th>\n",
       "      <th>1INCHBUSD</th>\n",
       "      <th>1INCHUSDT</th>\n",
       "      <th>ACABTC</th>\n",
       "      <th>ACABUSD</th>\n",
       "      <th>ACAUSDT</th>\n",
       "      <th>ACHBUSD</th>\n",
       "      <th>ACHUSDT</th>\n",
       "      <th>ACMBTC</th>\n",
       "      <th>ACMBUSD</th>\n",
       "      <th>...</th>\n",
       "      <th>ZILBUSD</th>\n",
       "      <th>ZILETH</th>\n",
       "      <th>ZILEUR</th>\n",
       "      <th>ZILTRY</th>\n",
       "      <th>ZILUSDT</th>\n",
       "      <th>ZRXBNB</th>\n",
       "      <th>ZRXBTC</th>\n",
       "      <th>ZRXBUSD</th>\n",
       "      <th>ZRXETH</th>\n",
       "      <th>ZRXUSDT</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>base_volume</th>\n",
       "      <th>base_volume</th>\n",
       "      <th>base_volume</th>\n",
       "      <th>base_volume</th>\n",
       "      <th>base_volume</th>\n",
       "      <th>base_volume</th>\n",
       "      <th>base_volume</th>\n",
       "      <th>base_volume</th>\n",
       "      <th>base_volume</th>\n",
       "      <th>base_volume</th>\n",
       "      <th>...</th>\n",
       "      <th>rolling_quote_volume</th>\n",
       "      <th>rolling_quote_volume</th>\n",
       "      <th>rolling_quote_volume</th>\n",
       "      <th>rolling_quote_volume</th>\n",
       "      <th>rolling_quote_volume</th>\n",
       "      <th>rolling_quote_volume</th>\n",
       "      <th>rolling_quote_volume</th>\n",
       "      <th>rolling_quote_volume</th>\n",
       "      <th>rolling_quote_volume</th>\n",
       "      <th>rolling_quote_volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-10-11 00:00:00</th>\n",
       "      <td>435.8</td>\n",
       "      <td>826.7</td>\n",
       "      <td>2290.9</td>\n",
       "      <td>16.68</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5779.35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72348.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>731893.803052</td>\n",
       "      <td>47.183341</td>\n",
       "      <td>14259.137445</td>\n",
       "      <td>5.424846e+06</td>\n",
       "      <td>6.792564e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.741655</td>\n",
       "      <td>23835.1569</td>\n",
       "      <td>10.447184</td>\n",
       "      <td>9.951928e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-11 11:30:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>734340.702259</td>\n",
       "      <td>46.665334</td>\n",
       "      <td>14278.038162</td>\n",
       "      <td>5.418066e+06</td>\n",
       "      <td>6.817638e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.720068</td>\n",
       "      <td>23770.8243</td>\n",
       "      <td>10.492221</td>\n",
       "      <td>1.001443e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-11 12:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>736617.949352</td>\n",
       "      <td>46.653747</td>\n",
       "      <td>14292.860899</td>\n",
       "      <td>5.413442e+06</td>\n",
       "      <td>6.830076e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.717524</td>\n",
       "      <td>23809.6313</td>\n",
       "      <td>10.492221</td>\n",
       "      <td>1.003301e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 11444 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "symbol                 1INCHBTC   1INCHBUSD   1INCHUSDT      ACABTC  \\\n",
       "                    base_volume base_volume base_volume base_volume   \n",
       "date                                                                  \n",
       "2022-10-11 00:00:00       435.8       826.7      2290.9       16.68   \n",
       "2022-10-11 11:30:00         0.0         0.0         0.0        0.00   \n",
       "2022-10-11 12:00:00         0.0         0.0         0.0        0.00   \n",
       "\n",
       "symbol                  ACABUSD     ACAUSDT     ACHBUSD     ACHUSDT  \\\n",
       "                    base_volume base_volume base_volume base_volume   \n",
       "date                                                                  \n",
       "2022-10-11 00:00:00         0.0     5779.35         0.0     72348.0   \n",
       "2022-10-11 11:30:00         0.0        0.00         0.0         0.0   \n",
       "2022-10-11 12:00:00         0.0        0.00         0.0         0.0   \n",
       "\n",
       "symbol                   ACMBTC     ACMBUSD  ...              ZILBUSD  \\\n",
       "                    base_volume base_volume  ... rolling_quote_volume   \n",
       "date                                         ...                        \n",
       "2022-10-11 00:00:00         0.0         0.0  ...        731893.803052   \n",
       "2022-10-11 11:30:00         0.0         0.0  ...        734340.702259   \n",
       "2022-10-11 12:00:00         0.0         0.0  ...        736617.949352   \n",
       "\n",
       "symbol                            ZILETH               ZILEUR  \\\n",
       "                    rolling_quote_volume rolling_quote_volume   \n",
       "date                                                            \n",
       "2022-10-11 00:00:00            47.183341         14259.137445   \n",
       "2022-10-11 11:30:00            46.665334         14278.038162   \n",
       "2022-10-11 12:00:00            46.653747         14292.860899   \n",
       "\n",
       "symbol                            ZILTRY              ZILUSDT  \\\n",
       "                    rolling_quote_volume rolling_quote_volume   \n",
       "date                                                            \n",
       "2022-10-11 00:00:00         5.424846e+06         6.792564e+06   \n",
       "2022-10-11 11:30:00         5.418066e+06         6.817638e+06   \n",
       "2022-10-11 12:00:00         5.413442e+06         6.830076e+06   \n",
       "\n",
       "symbol                            ZRXBNB               ZRXBTC  \\\n",
       "                    rolling_quote_volume rolling_quote_volume   \n",
       "date                                                            \n",
       "2022-10-11 00:00:00                  0.0             2.741655   \n",
       "2022-10-11 11:30:00                  0.0             2.720068   \n",
       "2022-10-11 12:00:00                  0.0             2.717524   \n",
       "\n",
       "symbol                           ZRXBUSD               ZRXETH  \\\n",
       "                    rolling_quote_volume rolling_quote_volume   \n",
       "date                                                            \n",
       "2022-10-11 00:00:00           23835.1569            10.447184   \n",
       "2022-10-11 11:30:00           23770.8243            10.492221   \n",
       "2022-10-11 12:00:00           23809.6313            10.492221   \n",
       "\n",
       "symbol                           ZRXUSDT  \n",
       "                    rolling_quote_volume  \n",
       "date                                      \n",
       "2022-10-11 00:00:00         9.951928e+05  \n",
       "2022-10-11 11:30:00         1.001443e+06  \n",
       "2022-10-11 12:00:00         1.003301e+06  \n",
       "\n",
       "[3 rows x 11444 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "crypto_output_log_15s = 'crypto_logs/crypto_output_log_15s.txt'\n",
    "df_15s = pd.read_csv(crypto_output_log_15s, header=[0, 1], index_col=0)\n",
    "df_15s.index = pd.DatetimeIndex(df_15s.index)\n",
    "df_15s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>base_volume</th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>open</th>\n",
       "      <th>quote_volume</th>\n",
       "      <th>rolling_base_volume</th>\n",
       "      <th>rolling_quote_volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-10-11 00:00:00</th>\n",
       "      <td>1578.1</td>\n",
       "      <td>2.779</td>\n",
       "      <td>2.780</td>\n",
       "      <td>2.774</td>\n",
       "      <td>2.774</td>\n",
       "      <td>4343.165</td>\n",
       "      <td>1293406.6</td>\n",
       "      <td>3.748034e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-11 11:30:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.784</td>\n",
       "      <td>2.784</td>\n",
       "      <td>2.774</td>\n",
       "      <td>2.774</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1284324.2</td>\n",
       "      <td>3.720728e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-11 12:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.791</td>\n",
       "      <td>2.791</td>\n",
       "      <td>2.774</td>\n",
       "      <td>2.774</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1285215.9</td>\n",
       "      <td>3.723047e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     base_volume  close   high    low   open  quote_volume  \\\n",
       "date                                                                         \n",
       "2022-10-11 00:00:00       1578.1  2.779  2.780  2.774  2.774      4343.165   \n",
       "2022-10-11 11:30:00          0.0  2.784  2.784  2.774  2.774         0.000   \n",
       "2022-10-11 12:00:00          0.0  2.791  2.791  2.774  2.774         0.000   \n",
       "\n",
       "                     rolling_base_volume  rolling_quote_volume  \n",
       "date                                                            \n",
       "2022-10-11 00:00:00            1293406.6          3.748034e+06  \n",
       "2022-10-11 11:30:00            1284324.2          3.720728e+06  \n",
       "2022-10-11 12:00:00            1285215.9          3.723047e+06  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_15s[symbol]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>symbol</th>\n",
       "      <th>1INCHBTC</th>\n",
       "      <th>1INCHBUSD</th>\n",
       "      <th>1INCHUSDT</th>\n",
       "      <th>ACABTC</th>\n",
       "      <th>ACABUSD</th>\n",
       "      <th>ACAUSDT</th>\n",
       "      <th>ACHBUSD</th>\n",
       "      <th>ACHUSDT</th>\n",
       "      <th>ACMBTC</th>\n",
       "      <th>ACMBUSD</th>\n",
       "      <th>...</th>\n",
       "      <th>ZILBUSD</th>\n",
       "      <th>ZILETH</th>\n",
       "      <th>ZILEUR</th>\n",
       "      <th>ZILTRY</th>\n",
       "      <th>ZILUSDT</th>\n",
       "      <th>ZRXBNB</th>\n",
       "      <th>ZRXBTC</th>\n",
       "      <th>ZRXBUSD</th>\n",
       "      <th>ZRXETH</th>\n",
       "      <th>ZRXUSDT</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>base_volume</th>\n",
       "      <th>base_volume</th>\n",
       "      <th>base_volume</th>\n",
       "      <th>base_volume</th>\n",
       "      <th>base_volume</th>\n",
       "      <th>base_volume</th>\n",
       "      <th>base_volume</th>\n",
       "      <th>base_volume</th>\n",
       "      <th>base_volume</th>\n",
       "      <th>base_volume</th>\n",
       "      <th>...</th>\n",
       "      <th>rolling_quote_volume</th>\n",
       "      <th>rolling_quote_volume</th>\n",
       "      <th>rolling_quote_volume</th>\n",
       "      <th>rolling_quote_volume</th>\n",
       "      <th>rolling_quote_volume</th>\n",
       "      <th>rolling_quote_volume</th>\n",
       "      <th>rolling_quote_volume</th>\n",
       "      <th>rolling_quote_volume</th>\n",
       "      <th>rolling_quote_volume</th>\n",
       "      <th>rolling_quote_volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-10-11 00:00:00</th>\n",
       "      <td>435.8</td>\n",
       "      <td>826.7</td>\n",
       "      <td>2290.9</td>\n",
       "      <td>16.68</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5779.35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72348.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>731893.803052</td>\n",
       "      <td>47.183341</td>\n",
       "      <td>14259.137445</td>\n",
       "      <td>5.424846e+06</td>\n",
       "      <td>6.792564e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.741655</td>\n",
       "      <td>23835.1569</td>\n",
       "      <td>10.447184</td>\n",
       "      <td>9.951928e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-11 00:00:15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-11 00:00:30</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-11 00:00:45</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-11 00:01:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-11 11:59:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-11 11:59:15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-11 11:59:30</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-11 11:59:45</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-11 12:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>736617.949352</td>\n",
       "      <td>46.653747</td>\n",
       "      <td>14292.860899</td>\n",
       "      <td>5.413442e+06</td>\n",
       "      <td>6.830076e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.717524</td>\n",
       "      <td>23809.6313</td>\n",
       "      <td>10.492221</td>\n",
       "      <td>1.003301e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2881 rows Ã— 11444 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "symbol                 1INCHBTC   1INCHBUSD   1INCHUSDT      ACABTC  \\\n",
       "                    base_volume base_volume base_volume base_volume   \n",
       "date                                                                  \n",
       "2022-10-11 00:00:00       435.8       826.7      2290.9       16.68   \n",
       "2022-10-11 00:00:15         NaN         NaN         NaN         NaN   \n",
       "2022-10-11 00:00:30         NaN         NaN         NaN         NaN   \n",
       "2022-10-11 00:00:45         NaN         NaN         NaN         NaN   \n",
       "2022-10-11 00:01:00         NaN         NaN         NaN         NaN   \n",
       "...                         ...         ...         ...         ...   \n",
       "2022-10-11 11:59:00         NaN         NaN         NaN         NaN   \n",
       "2022-10-11 11:59:15         NaN         NaN         NaN         NaN   \n",
       "2022-10-11 11:59:30         NaN         NaN         NaN         NaN   \n",
       "2022-10-11 11:59:45         NaN         NaN         NaN         NaN   \n",
       "2022-10-11 12:00:00         0.0         0.0         0.0        0.00   \n",
       "\n",
       "symbol                  ACABUSD     ACAUSDT     ACHBUSD     ACHUSDT  \\\n",
       "                    base_volume base_volume base_volume base_volume   \n",
       "date                                                                  \n",
       "2022-10-11 00:00:00         0.0     5779.35         0.0     72348.0   \n",
       "2022-10-11 00:00:15         NaN         NaN         NaN         NaN   \n",
       "2022-10-11 00:00:30         NaN         NaN         NaN         NaN   \n",
       "2022-10-11 00:00:45         NaN         NaN         NaN         NaN   \n",
       "2022-10-11 00:01:00         NaN         NaN         NaN         NaN   \n",
       "...                         ...         ...         ...         ...   \n",
       "2022-10-11 11:59:00         NaN         NaN         NaN         NaN   \n",
       "2022-10-11 11:59:15         NaN         NaN         NaN         NaN   \n",
       "2022-10-11 11:59:30         NaN         NaN         NaN         NaN   \n",
       "2022-10-11 11:59:45         NaN         NaN         NaN         NaN   \n",
       "2022-10-11 12:00:00         0.0        0.00         0.0         0.0   \n",
       "\n",
       "symbol                   ACMBTC     ACMBUSD  ...              ZILBUSD  \\\n",
       "                    base_volume base_volume  ... rolling_quote_volume   \n",
       "date                                         ...                        \n",
       "2022-10-11 00:00:00         0.0         0.0  ...        731893.803052   \n",
       "2022-10-11 00:00:15         NaN         NaN  ...                  NaN   \n",
       "2022-10-11 00:00:30         NaN         NaN  ...                  NaN   \n",
       "2022-10-11 00:00:45         NaN         NaN  ...                  NaN   \n",
       "2022-10-11 00:01:00         NaN         NaN  ...                  NaN   \n",
       "...                         ...         ...  ...                  ...   \n",
       "2022-10-11 11:59:00         NaN         NaN  ...                  NaN   \n",
       "2022-10-11 11:59:15         NaN         NaN  ...                  NaN   \n",
       "2022-10-11 11:59:30         NaN         NaN  ...                  NaN   \n",
       "2022-10-11 11:59:45         NaN         NaN  ...                  NaN   \n",
       "2022-10-11 12:00:00         0.0         0.0  ...        736617.949352   \n",
       "\n",
       "symbol                            ZILETH               ZILEUR  \\\n",
       "                    rolling_quote_volume rolling_quote_volume   \n",
       "date                                                            \n",
       "2022-10-11 00:00:00            47.183341         14259.137445   \n",
       "2022-10-11 00:00:15                  NaN                  NaN   \n",
       "2022-10-11 00:00:30                  NaN                  NaN   \n",
       "2022-10-11 00:00:45                  NaN                  NaN   \n",
       "2022-10-11 00:01:00                  NaN                  NaN   \n",
       "...                                  ...                  ...   \n",
       "2022-10-11 11:59:00                  NaN                  NaN   \n",
       "2022-10-11 11:59:15                  NaN                  NaN   \n",
       "2022-10-11 11:59:30                  NaN                  NaN   \n",
       "2022-10-11 11:59:45                  NaN                  NaN   \n",
       "2022-10-11 12:00:00            46.653747         14292.860899   \n",
       "\n",
       "symbol                            ZILTRY              ZILUSDT  \\\n",
       "                    rolling_quote_volume rolling_quote_volume   \n",
       "date                                                            \n",
       "2022-10-11 00:00:00         5.424846e+06         6.792564e+06   \n",
       "2022-10-11 00:00:15                  NaN                  NaN   \n",
       "2022-10-11 00:00:30                  NaN                  NaN   \n",
       "2022-10-11 00:00:45                  NaN                  NaN   \n",
       "2022-10-11 00:01:00                  NaN                  NaN   \n",
       "...                                  ...                  ...   \n",
       "2022-10-11 11:59:00                  NaN                  NaN   \n",
       "2022-10-11 11:59:15                  NaN                  NaN   \n",
       "2022-10-11 11:59:30                  NaN                  NaN   \n",
       "2022-10-11 11:59:45                  NaN                  NaN   \n",
       "2022-10-11 12:00:00         5.413442e+06         6.830076e+06   \n",
       "\n",
       "symbol                            ZRXBNB               ZRXBTC  \\\n",
       "                    rolling_quote_volume rolling_quote_volume   \n",
       "date                                                            \n",
       "2022-10-11 00:00:00                  0.0             2.741655   \n",
       "2022-10-11 00:00:15                  NaN                  NaN   \n",
       "2022-10-11 00:00:30                  NaN                  NaN   \n",
       "2022-10-11 00:00:45                  NaN                  NaN   \n",
       "2022-10-11 00:01:00                  NaN                  NaN   \n",
       "...                                  ...                  ...   \n",
       "2022-10-11 11:59:00                  NaN                  NaN   \n",
       "2022-10-11 11:59:15                  NaN                  NaN   \n",
       "2022-10-11 11:59:30                  NaN                  NaN   \n",
       "2022-10-11 11:59:45                  NaN                  NaN   \n",
       "2022-10-11 12:00:00                  0.0             2.717524   \n",
       "\n",
       "symbol                           ZRXBUSD               ZRXETH  \\\n",
       "                    rolling_quote_volume rolling_quote_volume   \n",
       "date                                                            \n",
       "2022-10-11 00:00:00           23835.1569            10.447184   \n",
       "2022-10-11 00:00:15                  NaN                  NaN   \n",
       "2022-10-11 00:00:30                  NaN                  NaN   \n",
       "2022-10-11 00:00:45                  NaN                  NaN   \n",
       "2022-10-11 00:01:00                  NaN                  NaN   \n",
       "...                                  ...                  ...   \n",
       "2022-10-11 11:59:00                  NaN                  NaN   \n",
       "2022-10-11 11:59:15                  NaN                  NaN   \n",
       "2022-10-11 11:59:30                  NaN                  NaN   \n",
       "2022-10-11 11:59:45                  NaN                  NaN   \n",
       "2022-10-11 12:00:00           23809.6313            10.492221   \n",
       "\n",
       "symbol                           ZRXUSDT  \n",
       "                    rolling_quote_volume  \n",
       "date                                      \n",
       "2022-10-11 00:00:00         9.951928e+05  \n",
       "2022-10-11 00:00:15                  NaN  \n",
       "2022-10-11 00:00:30                  NaN  \n",
       "2022-10-11 00:00:45                  NaN  \n",
       "2022-10-11 00:01:00                  NaN  \n",
       "...                                  ...  \n",
       "2022-10-11 11:59:00                  NaN  \n",
       "2022-10-11 11:59:15                  NaN  \n",
       "2022-10-11 11:59:30                  NaN  \n",
       "2022-10-11 11:59:45                  NaN  \n",
       "2022-10-11 12:00:00         1.003301e+06  \n",
       "\n",
       "[2881 rows x 11444 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_15s.resample('15s').agg('max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "crypto_output_log_1min = 'crypto_logs/crypto_output_log_1min.txt'\n",
    "df_1min = pd.read_csv(crypto_output_log_1min, header=[0, 1], index_col=0)\n",
    "df_1min.index = pd.DatetimeIndex(df_1min.index)\n",
    "df_1min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1min[symbol]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1min[symbol].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_1min.copy()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.swaplevel(0, 1)\n",
    "df = df.stack(level=1).reset_index(level=1)\n",
    "df_temp = df[['base_volume', 'quote_volume', \n",
    "              'rolling_base_volume', 'rolling_quote_volume']]\n",
    "df_temp[df_temp['pair'] == 'base_volume'].iloc[:,1:] = \\\n",
    "    df_temp[df_temp['pair'] == 'rolling_base_volume'].iloc[:,1:].diff(1) + \\\n",
    "    df_temp[df_temp['pair'] == 'base_volume'].iloc[:,1:].shift(1440)\n",
    "df_temp[df_temp['pair'] == 'quote_volume'].iloc[:,1:] = \\\n",
    "    df_temp[df_temp['pair'] == 'rolling_quote_volume'].iloc[:,1:].diff(1) + \\\n",
    "    df_temp[df_temp['pair'] == 'quote_volume'].iloc[:,1:].shift(1440)\n",
    "df = df.reset_index().pivot_table(index=['date'], columns=['pair'], \n",
    "                                  values=df.columns[1:])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_1min.copy()\n",
    "df = df.iloc[-1440:]\n",
    "df_old = df.copy().iloc[:-10]\n",
    "df.columns = df.columns.swaplevel(0, 1)\n",
    "df = df.sort_index(axis='columns').drop(columns=['base_volume', 'quote_volume'])\n",
    "df.columns = df.columns.swaplevel(0, 1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[symbol]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_1min.copy()\n",
    "df = df.iloc[-1440:]\n",
    "df_old = df.copy().iloc[:-10]\n",
    "df.columns = df.columns.swaplevel(0, 1)\n",
    "df = df.sort_index(axis='columns').drop(columns=['rolling_base_volume', 'rolling_quote_volume'])\n",
    "df.columns = df.columns.swaplevel(0, 1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = df.groupby('pair', axis='columns', level=1)\n",
    "grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[symbol]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = df.groupby('pair', axis='columns').describe()\n",
    "grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(level=0, axis=1).apply(lambda x: x[x.name].apply(lambda x: x, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(level='symbol', axis='index')['base_volume']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(level='pair', axis='columns').apply(lambda x: x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(level=['symbol', 'pair'], axis='columns').agg(lambda x: x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('pair', axis=1).apply(lambda x: x[x.name == 'base_volume'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('pair', axis=1, level=1).apply(lambda x: x.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:,(slice(None), 'base_volume')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_1min.copy()\n",
    "idx = pd.IndexSlice\n",
    "#df_base_volume = df.loc[:,idx[:,'base_volume']]\n",
    "#df_quote_volume = df.loc[:,idx[:,'quote_volume']]\n",
    "#df_rolling_base_volume = df.loc[:,idx[:,'rolling_base_volume']]\n",
    "#df_rolling_quote_volume = df.loc[:,idx[:,'rolling_quote_volume']]\n",
    "df_volume = df.loc[:,idx[:,['base_volume', 'quote_volume', 'rolling_quote_volume', 'rolling_quote_volume']]].copy()\n",
    "#df_base_volume = df_rolling_base_volume.droplevel(1, axis=1).diff(1) + df_base_volume.droplevel(1, axis=1).shift(1440)\n",
    "#df_quote_volume = df_rolling_quote_volume.droplevel(1, axis=1).diff(1) + df_quote_volume.droplevel(1, axis=1).shift(1440)\n",
    "#df = pd.merge(left=df, right=df_rolling_base_volume, how='right')\n",
    "#df = pd.merge(left=df, right=df_rolling_quote_volume, how='right')\n",
    "#df.loc[:,(slice(None), 'base_volume')] = df_base_volume\n",
    "#df.loc[:,(slice(None), 'quote_volume')] = df_quote_volume\n",
    "#df.loc[:,idx[:,'base_volume']] = \\\n",
    "#    df.loc[:,idx[:,'rolling_base_volume']].diff(1) + \\\n",
    "#    df.loc[:,idx[:,'base_volume']].shift(1440)\n",
    "#df.loc[:,idx[:,'quote_volume']] = \\\n",
    "#    df.loc[:,idx[:,'rolling_quote_volume']].diff(1) + \\\n",
    "#    df.loc[:,idx[:,'quote_volume']].shift(1440)\n",
    "#df['BTCUSDT'].tail(10)\n",
    "df_volume #.loc[:,idx[:,'base_volume']] + df_volume.loc[:,idx[:,'rolling_base_volume']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_1min.copy()\n",
    "t1 = time()\n",
    "df.iloc[:,df.columns.get_level_values(1) == 'base_volume'] = \\\n",
    "    df.xs('rolling_base_volume', axis=1, level=1).diff(1) + \\\n",
    "    df.xs('base_volume', axis=1, level=1).shift(1440)\n",
    "df.iloc[:,df.columns.get_level_values(1) == 'quote_volume'] = \\\n",
    "    df.xs('rolling_quote_volume', axis=1, level=1).diff(1) + \\\n",
    "    df.xs('quote_volume', axis=1, level=1).shift(1440)\n",
    "t2 = time()\n",
    "print('It took', t2 - t1, 'seconds')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[symbol]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "def recalculate_volumes(df):\n",
    "    df = df.stack(level=1)\n",
    "    df.reset_index(level=1, inplace=True)\n",
    "    df[df['pair'] == 'base_volume'].iloc[:,1:] = \\\n",
    "        df[df['pair'] == 'rolling_base_volume'].iloc[:,1:].diff(1) + \\\n",
    "        df[df['pair'] == 'base_volume'].iloc[:,1:].shift(1440)\n",
    "    df[df['pair'] == 'quote_volume'].iloc[:,1:] = \\\n",
    "        df[df['pair'] == 'rolling_quote_volume'].iloc[:,1:].diff(1) + \\\n",
    "        df[df['pair'] == 'quote_volume'].iloc[:,1:].shift(1440)\n",
    "    df.reset_index(inplace=True)\n",
    "    df = df.pivot_table(index=['date'], columns=['pair'], values=df.columns[1:], sort=False)\n",
    "    #df.columns = df.columns.swaplevel(0, 1)\n",
    "    #df = df[['open', 'high', 'low', 'close', \n",
    "    #         'base_volume', 'quote_volume', \n",
    "    #         'rolling_base_volume', \n",
    "    #         'rolling_quote_volume']]\n",
    "    #df.columns = df.columns.swaplevel(0, 1)\n",
    "    return df\n",
    "\n",
    "df = df_1min.copy()\n",
    "t1 = time()\n",
    "df = recalculate_volumes(df)\n",
    "t2 = time()\n",
    "print('It took', t2 - t1, 'seconds')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[symbol]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[symbol]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "df = df.stack(level=1).reset_index(level=1)\n",
    "df[df['pair'] == 'base_volume'].iloc[:,1:] = \\\n",
    "    df[df['pair'] == 'rolling_base_volume'].iloc[:,1:].diff(1) + \\\n",
    "    df[df['pair'] == 'base_volume'].iloc[:,1:].shift(1440)\n",
    "df[df['pair'] == 'quote_volume'].iloc[:,1:] = \\\n",
    "    df[df['pair'] == 'rolling_quote_volume'].iloc[:,1:].diff(1) + \\\n",
    "    df[df['pair'] == 'quote_volume'].iloc[:,1:].shift(1440)\n",
    "df = df.reset_index().pivot_table(index=['date'], columns=['pair'], \n",
    "                                  values=df.columns[1:])\n",
    "df.columns = df.columns.swaplevel(0, 1)\n",
    "df = df[['open', 'high', 'low', 'close', \n",
    "         'base_volume', 'quote_volume', \n",
    "         'rolling_base_volume', \n",
    "         'rolling_quote_volume']]\n",
    "df.columns = df.columns.swaplevel(0, 1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.swaplevel(0, 1)\n",
    "df_old.columns = df_old.columns.swaplevel(0, 1)\n",
    "df = pd.concat([df, df_old[['base_volume', 'quote_volume']]], \n",
    "               join='outer', axis='columns')\n",
    "df.columns = df.columns.swaplevel(0, 1)\n",
    "df = df.stack(level=1).reset_index(level=1)\n",
    "df[df['pair'] == 'base_volume'].iloc[:,1:] = \\\n",
    "    df[df['pair'] == 'rolling_base_volume'].iloc[:,1:].diff(1) + \\\n",
    "    df[df['pair'] == 'base_volume'].iloc[:,1:].shift(1440)\n",
    "df[df['pair'] == 'quote_volume'].iloc[:,1:] = \\\n",
    "    df[df['pair'] == 'rolling_quote_volume'].iloc[:,1:].diff(1) + \\\n",
    "    df[df['pair'] == 'quote_volume'].iloc[:,1:].shift(1440)\n",
    "df = df.reset_index().pivot_table(index=['date'], columns=['pair'], \n",
    "                                  values=df.columns[1:])\n",
    "df.columns = df.columns.swaplevel(0, 1)\n",
    "df = df[['open', 'high', 'low', 'close', \n",
    "         'base_volume', 'quote_volume', \n",
    "         'rolling_base_volume', \n",
    "         'rolling_quote_volume']]\n",
    "df.columns = df.columns.swaplevel(0, 1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['BTCUSDT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recalculate_volumes(df, df_old):\n",
    "    df.columns = df.columns.swaplevel(0, 1)\n",
    "    df_old.columns = df_old.columns.swaplevel(0, 1)\n",
    "    df = pd.concat([df, df_old[['base_volume', 'quote_volume']]], \n",
    "                   join='outer', axis='columns')\n",
    "    df.columns = df.columns.swaplevel(0, 1)\n",
    "    df = df.stack(level=1).reset_index(level=1)\n",
    "    df[df['pair'] == 'base_volume'].iloc[:,1:] = \\\n",
    "        df[df['pair'] == 'rolling_base_volume'].iloc[:,1:].diff(1) + \\\n",
    "        df[df['pair'] == 'base_volume'].iloc[:,1:].shift(1440)\n",
    "    df[df['pair'] == 'quote_volume'].iloc[:,1:] = \\\n",
    "        df[df['pair'] == 'rolling_quote_volume'].iloc[:,1:].diff(1) + \\\n",
    "        df[df['pair'] == 'quote_volume'].iloc[:,1:].shift(1440)\n",
    "    df = df.reset_index().pivot_table(index=['date'], columns=['pair'], \n",
    "                                      values=df.columns[1:])\n",
    "    df.columns = df.columns.swaplevel(0, 1)\n",
    "    df = df[['open', 'high', 'low', 'close', \n",
    "             'base_volume', 'quote_volume', \n",
    "             'rolling_base_volume', \n",
    "             'rolling_quote_volume']]\n",
    "    df.columns = df.columns.swaplevel(0, 1)\n",
    "    return df\n",
    "\n",
    "def resample(df, df_old):\n",
    "    interval = '1min'\n",
    "    df.index = pd.DatetimeIndex(df.index).round(interval)\n",
    "    df = df.stack(level=0).reset_index(level=1)\n",
    "    frequency = pd.tseries.frequencies.to_offset((df.index[1:] - df.index[:-1]).min())\n",
    "    frequency_1min = pd.tseries.frequencies.to_offset('1min')\n",
    "    if frequency > frequency_1min:\n",
    "        df = df.pivot_table(index=['date'], columns=['symbol'], \n",
    "                            values=['open', 'high', 'low', 'close', \n",
    "                                    'base_volume', 'quote_volume', \n",
    "                                    'rolling_base_volume', \n",
    "                                    'rolling_quote_volume'], \n",
    "                            aggfunc={'open': 'first', 'high': 'max', \n",
    "                                     'low': 'min', 'close': 'last', \n",
    "                                     'base_volume': 'sum', \n",
    "                                     'quote_volume': 'sum', \n",
    "                                     'rolling_base_volume': 'sum', \n",
    "                                     'rolling_quote_volume': 'sum'})\n",
    "    else:\n",
    "        df = df.pivot_table(index=['date'], columns=['symbol'], \n",
    "                            values=['open', 'high', 'low', 'close', \n",
    "                                    'rolling_base_volume', \n",
    "                                    'rolling_quote_volume'], \n",
    "                            aggfunc={'open': 'first', 'high': 'max', \n",
    "                                     'low': 'min', 'close': 'last', \n",
    "                                     'rolling_base_volume': 'max', \n",
    "                                     'rolling_quote_volume': 'max'})\n",
    "\n",
    "    #if frequency == frequency_1min:\n",
    "    #df = recalculate_volumes(df, df_old)\n",
    "\n",
    "    df.columns = df.columns.swaplevel(0, 1)\n",
    "    return df.sort_index()\n",
    "\n",
    "#df_old = None\n",
    "df1 = resample(df, df_old)\n",
    "#df1.columns = df1.columns.swaplevel(0, 1)\n",
    "#df1 = recalculate_volumes(df1, df_old)\n",
    "#df1.columns = df1.columns.swaplevel(0, 1)\n",
    "df1[symbol].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[symbol].resample('30s').agg('max').fillna(method='pad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[df1['pair'] == 'quote_volume']['ZILBUSD'].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[df1['pair'] == 'quote_volume']['ZILBUSD'].dropna().loc[:df['ZILBUSD']['quote_volume'].dropna().index[-1]].tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ZILBUSD']['quote_volume'].dropna().tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interval = '1min'\n",
    "df1 = df.copy()\n",
    "df1.index = pd.DatetimeIndex(df1.index).round(interval)\n",
    "df1 = df1.stack(level=0).reset_index(level=1)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interval = '1min'\n",
    "df1 = df.copy()\n",
    "df1.index = pd.DatetimeIndex(df1.index).round(interval)\n",
    "df1 = df1.stack(level=0).reset_index(level=1)\n",
    "df1 = df1.pivot_table(index=['date'], columns=['symbol'], \n",
    "                      values=['open', 'high', 'low', 'close', \n",
    "                              'base_volume', 'quote_volume', \n",
    "                              'rolling_base_volume', \n",
    "                              'rolling_quote_volume'], \n",
    "                      aggfunc={'open': 'first', 'high': 'max', \n",
    "                               'low': 'min', 'close': 'last', \n",
    "                               'base_volume': 'sum', \n",
    "                               'quote_volume': 'sum', \n",
    "                               'rolling_base_volume': 'sum', \n",
    "                               'rolling_quote_volume': 'sum'})\n",
    "#df1['base_volume'] = df1['base_volume'].fillna(0)\n",
    "#df1['quote_volume'] = df1['quote_volume'].fillna(0)\n",
    "#df1['rolling_base_volume'] = df1['rolling_base_volume'].fillna(0)\n",
    "#df1['rolling_quote_volume'] = df1['rolling_quote_volume'].fillna(0)\n",
    "df1.columns = df1.columns.swaplevel(0, 1)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['ZILBUSD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interval = '1min'\n",
    "df.index = pd.DatetimeIndex(df.index).round(interval)\n",
    "df = df.stack(level=0).reset_index(level=1)\n",
    "frequency = pd.tseries.frequencies.to_offset(df.index[1] - df.index[0])\n",
    "frequency_1min = pd.tseries.frequencies.to_offset('1min')\n",
    "if frequency < frequency_1min:\n",
    "    df = df.pivot_table(index=['date'], columns=['symbol'], \n",
    "                        values=['open', 'high', 'low', 'close', \n",
    "                                'rolling_base_volume', \n",
    "                                'rolling_quote_volume'], \n",
    "                        aggfunc={'open': 'first', 'high': 'max', \n",
    "                                 'low': 'min', 'close': 'last', \n",
    "                                 'rolling_base_volume': 'max', \n",
    "                                 'rolling_quote_volume': 'max'})\n",
    "else:\n",
    "    df = df.pivot_table(index=['date'], columns=['symbol'], \n",
    "                        values=['open', 'high', 'low', 'close', \n",
    "                                'base_volume', 'quote_volume', \n",
    "                                'rolling_base_volume', \n",
    "                                'rolling_quote_volume'], \n",
    "                        aggfunc={'open': 'first', 'high': 'max', \n",
    "                                 'low': 'min', 'close': 'last', \n",
    "                                 'base_volume': 'sum', \n",
    "                                 'quote_volume': 'sum', \n",
    "                                 'rolling_base_volume': 'sum', \n",
    "                                 'rolling_quote_volume': 'sum'})\n",
    "    df['base_volume'] = df['base_volume'].fillna(0)\n",
    "    df['quote_volume'] = df['quote_volume'].fillna(0)\n",
    "\n",
    "df['rolling_base_volume'] = df['rolling_base_volume'].fillna(0)\n",
    "df['rolling_quote_volume'] = df['rolling_quote_volume'].fillna(0)\n",
    "\n",
    "if frequency == frequency_1min:\n",
    "    df['base_volume'] = \n",
    "\n",
    "df = df.fillna(method='pad').fillna(method='backfill')\n",
    "df.columns = df.columns.swaplevel(0, 1)\n",
    "return df.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from binance.client import Client\n",
    "client = Client()\n",
    "df = pd.DataFrame(client.get_ticker())\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['symbol'] == symbol]['volume']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['symbol'] == symbol]['quoteVolume']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(client.get_ticker())\n",
    "float(df[df['symbol'] == symbol]['volume'].iloc[-1]) * float(df[df['symbol'] == symbol]['lastPrice'].iloc[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "float(df[df['symbol'] == symbol]['lastQty'].iloc[-1]) * float(df[df['symbol'] == symbol]['lastPrice'].iloc[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#symbol = 'NEBLBUSD'\n",
    "from cryptocurrency.ohlcv import download_pair\n",
    "df = download_pair(client, symbol, interval='1m', period=2000)\n",
    "#df = df.loc[:df_1min.index[-1]]\n",
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quote_volume = df['quote_volume'] * df['close']\n",
    "quote_volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_rolling_volume = quote_volume.rolling('1440min').sum()\n",
    "new_rolling_volume.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_standard_volume = (new_rolling_volume.diff(1) + quote_volume.shift(1440))\n",
    "new_standard_volume.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.convolve((new_rolling_volume).rolling('1440min').agg(np.sum), np.array([1, 0]), 'same')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "\n",
    "crypto_output_log_15s = 'crypto_logs/crypto_output_log_15s.txt'\n",
    "df = read_csv(crypto_output_log_15s, header=[0, 1], index_col=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['NEBLBUSD']['volume']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.infer_freq(df.asfreq('1min').index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index.freq == pd.tseries.frequencies.to_offset('1min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['BTCUSDT'].drop(columns=['volume']).iloc[-100:].plot(figsize=(20, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this from local machine:\n",
    "#apt update\n",
    "#apt install -y openssh-server sshfs vde2\n",
    "#mkdir -p /home/samuel/workspace/crypto_logs/\n",
    "#dpipe /usr/lib/openssh/sftp-server = ssh sam@154.12.239.24 sshfs :/home/samuel/workspace/crypto_logs/ /home/sam/workspace/crypto_logs -o slave &"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "input_filtered = pd.read_csv(crypto_logger_output_1min.input_log_screened_name, header=None, \n",
    "                             index_col=0, names=['date', 'symbol', 'lastPrice'])\n",
    "input_filter = input_filtered['symbol']\n",
    "#input_filter = set(input_filter.tolist())\n",
    "input_filter.isin(df['baseAsset'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "\n",
    "crypto_input_log_1min = 'crypto_logs/crypto_input_log_1min.txt'\n",
    "df = pd.read_csv(crypto_input_log_1min, header=0, index_col=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol = 'BTCUSDT'\n",
    "interval = '1m'\n",
    "period = 2880\n",
    "\n",
    "from cryptocurrency.authentication import Cryptocurrency_authenticator\n",
    "from cryptocurrency.ohlcv import download_pair\n",
    "\n",
    "authenticator = Cryptocurrency_authenticator(use_keys=False, testnet=False)\n",
    "client = authenticator.spot_client\n",
    "\n",
    "df = download_pair(client=client, symbol=symbol, interval=interval, period=period)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df.astype('float32').memory_usage().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.memory_usage().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyO4csgmdyxBlfVzNgUhkI0X",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "crypto_bot",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
